{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "38f774bd17046d4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-18T13:22:45.114560900Z",
     "start_time": "2024-06-18T13:22:43.997817900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                            id                                  types_x  \\\n0  ChIJYcGr7GSb0S0RckePBrCWikw                           hotel, lodging   \n1  ChIJZbWX6Aia0S0R0tM3h1RZ1h8  indonesian_restaurant, restaurant, food   \n2  ChIJYyHbhgia0S0RzdjNXLmcf54     tourist_attraction, restaurant, food   \n3  ChIJ6zf9LJCb0S0RFv3BdLl61ZY           coffee_shop, cafe, food, store   \n4  ChIJxaITmQia0S0RyrbukE8vsJU     tourist_attraction, place_of_worship   \n\n                                              review    user_id  \\\n0  It has quite small room, and the hallway is qu...  user_2573   \n1  Surprisingly, a really good warung that’s hidd...  user_2062   \n2  Only had a fleeting visit here, came by coach,...  user_2348   \n3  One word, underrated! How come place like this...  user_1448   \n4  This temple is located in Singaraja, located i...  user_4426   \n\n   sentiment-score                                               name  \\\n0         0.506250  Singaraja Hotel (ex- POP! Hotel Hardys Singara...   \n1         0.606250                                     Warung Bik Juk   \n2         0.491667                   Harbour Tourist Area of Buleleng   \n3         0.672338                                      Abuela Coffee   \n4         0.569762                           Klenteng Ling Gwan Kiong   \n\n            primary-type  rating  rating-count  \n0                  hotel     4.1        2581.0  \n1  indonesian_restaurant     4.5         648.0  \n2     tourist_attraction     4.3        2800.0  \n3            coffee_shop     4.9         164.0  \n4       place_of_worship     4.6         142.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>types_x</th>\n      <th>review</th>\n      <th>user_id</th>\n      <th>sentiment-score</th>\n      <th>name</th>\n      <th>primary-type</th>\n      <th>rating</th>\n      <th>rating-count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ChIJYcGr7GSb0S0RckePBrCWikw</td>\n      <td>hotel, lodging</td>\n      <td>It has quite small room, and the hallway is qu...</td>\n      <td>user_2573</td>\n      <td>0.506250</td>\n      <td>Singaraja Hotel (ex- POP! Hotel Hardys Singara...</td>\n      <td>hotel</td>\n      <td>4.1</td>\n      <td>2581.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ChIJZbWX6Aia0S0R0tM3h1RZ1h8</td>\n      <td>indonesian_restaurant, restaurant, food</td>\n      <td>Surprisingly, a really good warung that’s hidd...</td>\n      <td>user_2062</td>\n      <td>0.606250</td>\n      <td>Warung Bik Juk</td>\n      <td>indonesian_restaurant</td>\n      <td>4.5</td>\n      <td>648.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ChIJYyHbhgia0S0RzdjNXLmcf54</td>\n      <td>tourist_attraction, restaurant, food</td>\n      <td>Only had a fleeting visit here, came by coach,...</td>\n      <td>user_2348</td>\n      <td>0.491667</td>\n      <td>Harbour Tourist Area of Buleleng</td>\n      <td>tourist_attraction</td>\n      <td>4.3</td>\n      <td>2800.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ChIJ6zf9LJCb0S0RFv3BdLl61ZY</td>\n      <td>coffee_shop, cafe, food, store</td>\n      <td>One word, underrated! How come place like this...</td>\n      <td>user_1448</td>\n      <td>0.672338</td>\n      <td>Abuela Coffee</td>\n      <td>coffee_shop</td>\n      <td>4.9</td>\n      <td>164.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ChIJxaITmQia0S0RyrbukE8vsJU</td>\n      <td>tourist_attraction, place_of_worship</td>\n      <td>This temple is located in Singaraja, located i...</td>\n      <td>user_4426</td>\n      <td>0.569762</td>\n      <td>Klenteng Ling Gwan Kiong</td>\n      <td>place_of_worship</td>\n      <td>4.6</td>\n      <td>142.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "places_data = pd.read_csv(\"final-dataset/main_dataset.csv\") \n",
    "reviews_data = pd.read_csv(\"final-dataset/review_dataset.csv\")  \n",
    "\n",
    "user_place_reviews = pd.merge(reviews_data,places_data, on='id')\n",
    "\n",
    "# drop review_number, lat long, address, url,status, phone, types_y, price-level,review 1-5\n",
    "user_place_reviews = user_place_reviews.drop(columns=['review_number', 'latitude', 'longitude', 'address', 'url', 'status', 'phone', 'types_y', 'price-level', 'review 1', 'review 2', 'review 3', 'review 4', 'review 5'])\n",
    "user_place_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                            id                                    types_x  \\\n0  ChIJYcGr7GSb0S0RckePBrCWikw                           [hotel, lodging]   \n1  ChIJZbWX6Aia0S0R0tM3h1RZ1h8  [indonesian_restaurant, restaurant, food]   \n2  ChIJYyHbhgia0S0RzdjNXLmcf54     [tourist_attraction, restaurant, food]   \n3  ChIJ6zf9LJCb0S0RFv3BdLl61ZY           [coffee_shop, cafe, food, store]   \n4  ChIJxaITmQia0S0RyrbukE8vsJU     [tourist_attraction, place_of_worship]   \n\n                                              review    user_id  \\\n0  It has quite small room, and the hallway is qu...  user_2573   \n1  Surprisingly, a really good warung that’s hidd...  user_2062   \n2  Only had a fleeting visit here, came by coach,...  user_2348   \n3  One word, underrated! How come place like this...  user_1448   \n4  This temple is located in Singaraja, located i...  user_4426   \n\n   sentiment-score                                               name  \\\n0         0.506250  Singaraja Hotel (ex- POP! Hotel Hardys Singara...   \n1         0.606250                                     Warung Bik Juk   \n2         0.491667                   Harbour Tourist Area of Buleleng   \n3         0.672338                                      Abuela Coffee   \n4         0.569762                           Klenteng Ling Gwan Kiong   \n\n            primary-type  rating  rating-count  airport  ...  \\\n0                  hotel     4.1        2581.0        0  ...   \n1  indonesian_restaurant     4.5         648.0        0  ...   \n2     tourist_attraction     4.3        2800.0        0  ...   \n3            coffee_shop     4.9         164.0        0  ...   \n4       place_of_worship     4.6         142.0        0  ...   \n\n   tourist_attraction  travel_agency  turkish_restaurant  university  \\\n0                   0              0                   0           0   \n1                   0              0                   0           0   \n2                   1              0                   0           0   \n3                   0              0                   0           0   \n4                   1              0                   0           0   \n\n   vegan_restaurant  vegetarian_restaurant  vietnamese_restaurant  \\\n0                 0                      0                      0   \n1                 0                      0                      0   \n2                 0                      0                      0   \n3                 0                      0                      0   \n4                 0                      0                      0   \n\n   wedding_venue  wholesaler  zoo  \n0              0           0    0  \n1              0           0    0  \n2              0           0    0  \n3              0           0    0  \n4              0           0    0  \n\n[5 rows x 135 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>types_x</th>\n      <th>review</th>\n      <th>user_id</th>\n      <th>sentiment-score</th>\n      <th>name</th>\n      <th>primary-type</th>\n      <th>rating</th>\n      <th>rating-count</th>\n      <th>airport</th>\n      <th>...</th>\n      <th>tourist_attraction</th>\n      <th>travel_agency</th>\n      <th>turkish_restaurant</th>\n      <th>university</th>\n      <th>vegan_restaurant</th>\n      <th>vegetarian_restaurant</th>\n      <th>vietnamese_restaurant</th>\n      <th>wedding_venue</th>\n      <th>wholesaler</th>\n      <th>zoo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ChIJYcGr7GSb0S0RckePBrCWikw</td>\n      <td>[hotel, lodging]</td>\n      <td>It has quite small room, and the hallway is qu...</td>\n      <td>user_2573</td>\n      <td>0.506250</td>\n      <td>Singaraja Hotel (ex- POP! Hotel Hardys Singara...</td>\n      <td>hotel</td>\n      <td>4.1</td>\n      <td>2581.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ChIJZbWX6Aia0S0R0tM3h1RZ1h8</td>\n      <td>[indonesian_restaurant, restaurant, food]</td>\n      <td>Surprisingly, a really good warung that’s hidd...</td>\n      <td>user_2062</td>\n      <td>0.606250</td>\n      <td>Warung Bik Juk</td>\n      <td>indonesian_restaurant</td>\n      <td>4.5</td>\n      <td>648.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ChIJYyHbhgia0S0RzdjNXLmcf54</td>\n      <td>[tourist_attraction, restaurant, food]</td>\n      <td>Only had a fleeting visit here, came by coach,...</td>\n      <td>user_2348</td>\n      <td>0.491667</td>\n      <td>Harbour Tourist Area of Buleleng</td>\n      <td>tourist_attraction</td>\n      <td>4.3</td>\n      <td>2800.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ChIJ6zf9LJCb0S0RFv3BdLl61ZY</td>\n      <td>[coffee_shop, cafe, food, store]</td>\n      <td>One word, underrated! How come place like this...</td>\n      <td>user_1448</td>\n      <td>0.672338</td>\n      <td>Abuela Coffee</td>\n      <td>coffee_shop</td>\n      <td>4.9</td>\n      <td>164.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ChIJxaITmQia0S0RyrbukE8vsJU</td>\n      <td>[tourist_attraction, place_of_worship]</td>\n      <td>This temple is located in Singaraja, located i...</td>\n      <td>user_4426</td>\n      <td>0.569762</td>\n      <td>Klenteng Ling Gwan Kiong</td>\n      <td>place_of_worship</td>\n      <td>4.6</td>\n      <td>142.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 135 columns</p>\n</div>"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "user_place_reviews['types_x'] = user_place_reviews['types_x'].str.split(', ')\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "one_hot = mlb.fit_transform(user_place_reviews['types_x'])\n",
    "\n",
    "one_hot_df = pd.DataFrame(one_hot, columns=mlb.classes_)\n",
    "\n",
    "user_place_reviews = pd.concat([user_place_reviews, one_hot_df], axis=1)\n",
    "\n",
    "user_place_reviews = user_place_reviews.drop_duplicates(subset=['user_id', 'id'])\n",
    "\n",
    "# user_place_reviews = user_place_reviews.drop(columns=['types_x'])\n",
    "\n",
    "user_place_reviews.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-18T13:22:45.329567800Z",
     "start_time": "2024-06-18T13:22:45.111562900Z"
    }
   },
   "id": "bee4dde90012a62c",
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1740/2597246789.py:46: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  user_preferences[place_types] = user_preferences[place_types].applymap(lambda x: 1 if x > 0 else 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": "     user_id  airport  american_restaurant  amusement_center  amusement_park  \\\n0     user_1        0                    0                 1               1   \n1    user_10        0                    0                 0               0   \n2   user_100        0                    0                 0               0   \n3  user_1000        0                    0                 0               0   \n4  user_1001        0                    0                 0               0   \n\n   art_gallery  athletic_field  atm  bakery  banquet_hall  ...  travel_agency  \\\n0            0               0    0       0             0  ...              0   \n1            0               0    0       0             0  ...              0   \n2            0               0    0       0             0  ...              0   \n3            0               0    0       0             0  ...              0   \n4            0               0    0       0             0  ...              0   \n\n   turkish_restaurant  university  vegan_restaurant  vegetarian_restaurant  \\\n0                   0           0                 0                      0   \n1                   0           0                 0                      0   \n2                   0           0                 0                      0   \n3                   0           0                 0                      0   \n4                   0           0                 0                      0   \n\n   vietnamese_restaurant  wedding_venue  wholesaler  zoo  parking  \n0                      0              0           0    0        0  \n1                      0              0           0    0        0  \n2                      0              0           0    0        0  \n3                      0              0           0    0        0  \n4                      0              0           0    0        0  \n\n[5 rows x 127 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>airport</th>\n      <th>american_restaurant</th>\n      <th>amusement_center</th>\n      <th>amusement_park</th>\n      <th>art_gallery</th>\n      <th>athletic_field</th>\n      <th>atm</th>\n      <th>bakery</th>\n      <th>banquet_hall</th>\n      <th>...</th>\n      <th>travel_agency</th>\n      <th>turkish_restaurant</th>\n      <th>university</th>\n      <th>vegan_restaurant</th>\n      <th>vegetarian_restaurant</th>\n      <th>vietnamese_restaurant</th>\n      <th>wedding_venue</th>\n      <th>wholesaler</th>\n      <th>zoo</th>\n      <th>parking</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>user_1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>user_10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>user_100</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>user_1000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>user_1001</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 127 columns</p>\n</div>"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# List of place type columns\n",
    "place_types = [\n",
    "    'airport', 'american_restaurant', 'amusement_center', 'amusement_park', 'art_gallery',\n",
    "    'athletic_field', 'atm', 'bakery', 'banquet_hall', 'bar', 'barbecue_restaurant',\n",
    "    'barber_shop', 'beauty_salon', 'bed_and_breakfast', 'bicycle_store', 'brazilian_restaurant',\n",
    "    'breakfast_restaurant', 'brunch_restaurant', 'cafe', 'campground', 'camping_cabin',\n",
    "    'car_rental', 'car_wash', 'cemetery', 'child_care_agency', 'chinese_restaurant', 'church',\n",
    "    'clothing_store', 'coffee_shop', 'community_center', 'consultant', 'convention_center', 'cottage',\n",
    "    'cultural_center', 'dog_park', 'event_venue', 'extended_stay_hotel', 'farm', 'farmstay',\n",
    "    'fast_food_restaurant', 'finance', 'fitness_center', 'florist', 'food', 'french_restaurant',\n",
    "    'furniture_store', 'general_contractor', 'gift_shop', 'golf_course', 'greek_restaurant',\n",
    "    'grocery_store', 'guest_house', 'gym', 'hair_care', 'hair_salon', 'hamburger_restaurant',\n",
    "    'health', 'heliport', 'hiking_area', 'hindu_temple', 'historical_landmark', 'home_goods_store',\n",
    "    'home_improvement_store', 'hostel', 'hotel', 'ice_cream_shop', 'indian_restaurant',\n",
    "    'indonesian_restaurant', 'italian_restaurant', 'japanese_restaurant', 'jewelry_store',\n",
    "    'korean_restaurant', 'lebanese_restaurant', 'library', 'liquor_store', 'lodging', 'market',\n",
    "    'meal_delivery', 'meal_takeaway', 'mediterranean_restaurant', 'mexican_restaurant',\n",
    "    'middle_eastern_restaurant', 'mosque', 'motel', 'movie_theater', 'museum', 'national_park',\n",
    "    'night_club', 'park', 'performing_arts_theater', 'pizza_restaurant',\n",
    "    'place_of_worship', 'playground', 'preschool', 'private_guest_room', 'ramen_restaurant',\n",
    "    'real_estate_agency', 'resort_hotel', 'rest_stop', 'restaurant', 'sandwich_shop', 'school',\n",
    "    'seafood_restaurant', 'shopping_mall', 'spa', 'spanish_restaurant', 'sporting_goods_store',\n",
    "    'sports_club', 'sports_complex', 'steak_house', 'store', 'supermarket', 'sushi_restaurant',\n",
    "    'swimming_pool', 'thai_restaurant', 'tourist_attraction', 'travel_agency', 'turkish_restaurant',\n",
    "    'university', 'vegan_restaurant', 'vegetarian_restaurant', 'vietnamese_restaurant',\n",
    "    'wedding_venue', 'wholesaler', 'zoo', 'parking'\n",
    "]\n",
    "\n",
    "\n",
    "# Sum the place type columns for each user to get their preferences\n",
    "user_preferences = user_place_reviews.groupby('user_id')[place_types].sum().reset_index()\n",
    "\n",
    "# Normalize the preferences\n",
    "user_preferences[place_types] = user_preferences[place_types].div(user_preferences[place_types].sum(axis=1), axis=0)\n",
    "\n",
    "# Replace non zero values with 1\n",
    "user_preferences[place_types] = user_preferences[place_types].applymap(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "user_preferences.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-18T13:22:45.620114900Z",
     "start_time": "2024-06-18T13:22:45.291678600Z"
    }
   },
   "id": "8c5e21af968d9aff",
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "773/773 [==============================] - 9s 10ms/step - loss: 1.3044 - val_loss: 0.3775\n",
      "Epoch 2/10\n",
      "773/773 [==============================] - 7s 9ms/step - loss: 0.1922 - val_loss: 0.1057\n",
      "Epoch 3/10\n",
      "773/773 [==============================] - 7s 9ms/step - loss: 0.0567 - val_loss: 0.0329\n",
      "Epoch 4/10\n",
      "773/773 [==============================] - 8s 10ms/step - loss: 0.0199 - val_loss: 0.0154\n",
      "Epoch 5/10\n",
      "773/773 [==============================] - 8s 10ms/step - loss: 0.0085 - val_loss: 0.0084\n",
      "Epoch 6/10\n",
      "773/773 [==============================] - 7s 10ms/step - loss: 0.0039 - val_loss: 0.0049\n",
      "Epoch 7/10\n",
      "773/773 [==============================] - 7s 9ms/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 8/10\n",
      "773/773 [==============================] - 7s 9ms/step - loss: 9.6715e-04 - val_loss: 0.0015\n",
      "Epoch 9/10\n",
      "773/773 [==============================] - 7s 9ms/step - loss: 5.1414e-04 - val_loss: 0.0011\n",
      "Epoch 10/10\n",
      "773/773 [==============================] - 7s 9ms/step - loss: 2.6702e-04 - val_loss: 6.4504e-04\n",
      "1/1 [==============================] - 0s 78ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tf-gpu/anaconda3/envs/tf-gpu-peko/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'restaurant'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_1740/1637410897.py\u001B[0m in \u001B[0;36m?\u001B[0;34m()\u001B[0m\n\u001B[1;32m     70\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mplace_ids\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     71\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     72\u001B[0m \u001B[0;31m# Example: Recommend based on multiple types\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     73\u001B[0m \u001B[0mtype_ids\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m'restaurant'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'hotel'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 74\u001B[0;31m \u001B[0mrecommended_places\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrecommend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtype_ids\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     75\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"Top recommended places based on types {type_ids}: {recommended_places}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     76\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_1740/1637410897.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(type_ids, top_n)\u001B[0m\n\u001B[1;32m     61\u001B[0m     \u001B[0;31m# Create DataFrame to store probabilities\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m     \u001B[0mprob_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpredictions\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtype_names\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     64\u001B[0m     \u001B[0;31m# Sort and get top_n recommendations\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 65\u001B[0;31m     \u001B[0mtop_recommendations\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mprob_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msort_values\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mby\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtype_ids\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mascending\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0miloc\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m:\u001B[0m\u001B[0mtop_n\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     66\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     67\u001B[0m     \u001B[0;31m# Extract place IDs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     68\u001B[0m     \u001B[0mplace_ids\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtop_recommendations\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/tf-gpu-peko/lib/python3.11/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001B[0m\n\u001B[1;32m   7168\u001B[0m                 \u001B[0;34mf\"Length of ascending ({len(ascending)})\"\u001B[0m  \u001B[0;31m# type: ignore[arg-type]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   7169\u001B[0m                 \u001B[0;34mf\" != length of by ({len(by)})\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   7170\u001B[0m             )\n\u001B[1;32m   7171\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mby\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 7172\u001B[0;31m             \u001B[0mkeys\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_label_or_level_values\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mby\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   7173\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   7174\u001B[0m             \u001B[0;31m# need to rewrap columns in Series to apply key function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   7175\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mkey\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/tf-gpu-peko/lib/python3.11/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(.0)\u001B[0m\n\u001B[0;32m-> 7172\u001B[0;31m         \u001B[0;34m...\u001B[0m     \u001B[0mkey\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margsort\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindex_natsorted\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"time\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/anaconda3/envs/tf-gpu-peko/lib/python3.11/site-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, key, axis)\u001B[0m\n\u001B[1;32m   1907\u001B[0m             \u001B[0mvalues\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mxs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mother_axes\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1908\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_is_level_reference\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1909\u001B[0m             \u001B[0mvalues\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maxes\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_level_values\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1910\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1911\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1912\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1913\u001B[0m         \u001B[0;31m# Check for duplicates\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1914\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mvalues\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'restaurant'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "reviews = user_place_reviews\n",
    "\n",
    "# Normalize sentiment-score to a 1-5 scale\n",
    "reviews['normalized_sentiment'] = 1 + 4 * (reviews['sentiment-score'] - reviews['sentiment-score'].min()) / (reviews['sentiment-score'].max() - reviews['sentiment-score'].min())\n",
    "\n",
    "# Merge datasets on user_id\n",
    "merged_data = pd.merge(user_preferences, reviews, on='user_id', how='left')\n",
    "\n",
    "# Fill missing values in reviews with default values\n",
    "merged_data.fillna({'normalized_sentiment': 3.0, 'primary-type': 'unknown'}, inplace=True)\n",
    "\n",
    "# One-hot encode user preferences\n",
    "user_pref_cols = user_preferences.columns[2:]  # Assuming first two columns are index and user_id\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "user_pref_encoded = onehot_encoder.fit_transform(user_preferences[user_pref_cols])\n",
    "\n",
    "# One-hot encode primary-type in reviews\n",
    "type_onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "type_encoded = type_onehot_encoder.fit_transform(merged_data[['primary-type']])\n",
    "\n",
    "# Define the input layers\n",
    "user_input = Input(shape=(user_pref_encoded.shape[1],), name='user_preferences')\n",
    "type_input = Input(shape=(type_encoded.shape[1],), name='primary_type')\n",
    "\n",
    "# Concatenate the inputs\n",
    "concat = concatenate([user_input, type_input], name='concatenate')\n",
    "\n",
    "# Add dense layers\n",
    "dense1 = Dense(128, activation='relu', name='dense1')(concat)\n",
    "dense2 = Dense(64, activation='relu', name='dense2')(dense1)\n",
    "output = Dense(type_encoded.shape[1], activation='softmax', name='output')(dense2)\n",
    "\n",
    "# Build the model\n",
    "model = Model(inputs=[user_input, type_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "# Prepare input data for training\n",
    "user_ids = merged_data['user_id']\n",
    "user_pref_encoded_dict = dict(zip(user_preferences['user_id'], user_pref_encoded))\n",
    "user_pref_encoded_list = np.array([user_pref_encoded_dict[uid] for uid in user_ids])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit([user_pref_encoded_list, type_encoded], type_encoded,epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Function to recommend places based on predicted probabilities\n",
    "def recommend(type_ids, top_n=10):\n",
    "    type_codes = type_onehot_encoder.transform(np.array(type_ids).reshape(-1, 1))\n",
    "    dummy_user_pref = np.zeros((type_codes.shape[0], user_pref_encoded.shape[1]))  # Dummy user preferences\n",
    "    predictions = model.predict([dummy_user_pref, type_codes])\n",
    "    \n",
    "    # Get original type names\n",
    "    type_names = type_onehot_encoder.get_feature_names_out(['primary-type'])\n",
    "    \n",
    "    # Create DataFrame to store probabilities\n",
    "    prob_df = pd.DataFrame(predictions, columns=type_names)\n",
    "    \n",
    "    # Sort and get top_n recommendations\n",
    "    top_recommendations = prob_df.sort_values(by=type_ids, axis=1, ascending=False).iloc[:, :top_n]\n",
    "    \n",
    "    # Extract place IDs\n",
    "    place_ids = top_recommendations.columns.tolist()\n",
    "    \n",
    "    return place_ids\n",
    "\n",
    "# Example: Recommend based on multiple types\n",
    "type_ids = ['restaurant', 'hotel']\n",
    "recommended_places = recommend(type_ids)\n",
    "print(f\"Top recommended places based on types {type_ids}: {recommended_places}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-18T13:24:04.072965500Z",
     "start_time": "2024-06-18T13:22:48.559576100Z"
    }
   },
   "id": "7de8fa5dd9f7a13c",
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " user_input (InputLayer)     [(None, 126)]                0         []                            \n",
      "                                                                                                  \n",
      " place_input (InputLayer)    [(None, 126)]                0         []                            \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 50)                   6350      ['user_input[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 50)                   6350      ['place_input[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 100)                  0         ['dense[0][0]',               \n",
      "                                                                     'dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 128)                  12928     ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 64)                   8256      ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 1)                    65        ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 33949 (132.61 KB)\n",
      "Trainable params: 33949 (132.61 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "\n",
    "# Hyperparameters\n",
    "embedding_dim = 50\n",
    "\n",
    "# User model\n",
    "user_input = Input(shape=(len(place_types),), name='user_input')\n",
    "user_embedding = Dense(embedding_dim, activation='relu')(user_input)\n",
    "\n",
    "# Place model\n",
    "place_input = Input(shape=(len(place_types),), name='place_input')\n",
    "place_embedding = Dense(embedding_dim, activation='relu')(place_input)\n",
    "\n",
    "# Concatenate user and place embeddings\n",
    "merged = Concatenate()([user_embedding, place_embedding])\n",
    "dense_1 = Dense(128, activation='relu')(merged)\n",
    "dense_2 = Dense(64, activation='relu')(dense_1)\n",
    "output = Dense(1, activation='sigmoid')(dense_2)\n",
    "\n",
    "# Create and compile the model\n",
    "model = Model(inputs=[user_input, place_input], outputs=output)\n",
    "model.compile(optimizer='SGD', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-18T11:09:59.319051800Z",
     "start_time": "2024-06-18T11:09:59.159596600Z"
    }
   },
   "id": "7b318c87d1f7f1a0",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Ensure user_preferences and data are correctly aligned and split the data accordingly\n",
    "user_preferences = user_place_reviews.groupby('user_id')[place_types].sum().reset_index()\n",
    "user_preferences[place_types] = user_preferences[place_types].div(user_preferences[place_types].sum(axis=1), axis=0)\n",
    "\n",
    "# Merge data with user preferences to align place features with user preferences\n",
    "merged_data = user_place_reviews.merge(user_preferences, on='user_id', suffixes=('', '_user'))\n",
    "\n",
    "# Prepare user features and place features for each review\n",
    "user_features = merged_data[[f'{ptype}_user' for ptype in place_types]].values\n",
    "place_features = merged_data[place_types].values\n",
    "\n",
    "# Generate labels (assuming binary relevance for simplicity)\n",
    "# You need to ensure your labels are the same length as user and place features\n",
    "labels = np.random.randint(2, size=(len(user_features),))\n",
    "\n",
    "# Split into train and test sets ensuring the lengths match\n",
    "user_train, user_test, place_train, place_test, y_train, y_test = train_test_split(\n",
    "    user_features, place_features, labels, test_size=0.3, random_state=42\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T22:02:47.702995200Z",
     "start_time": "2024-06-17T22:02:47.148732600Z"
    }
   },
   "id": "3bc2972329ebb950",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "676/676 [==============================] - 10s 12ms/step - loss: 0.6932 - accuracy: 0.5037 - val_loss: 0.6937 - val_accuracy: 0.4989\n",
      "Epoch 2/15\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.6932 - accuracy: 0.4999 - val_loss: 0.6933 - val_accuracy: 0.4927\n",
      "Epoch 3/15\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.6931 - accuracy: 0.5027 - val_loss: 0.6932 - val_accuracy: 0.4987\n",
      "Epoch 4/15\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.6930 - accuracy: 0.5079 - val_loss: 0.6935 - val_accuracy: 0.4996\n",
      "Epoch 5/15\n",
      "676/676 [==============================] - 11s 16ms/step - loss: 0.6929 - accuracy: 0.5092 - val_loss: 0.6932 - val_accuracy: 0.5022\n",
      "Epoch 6/15\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.6929 - accuracy: 0.5056 - val_loss: 0.6934 - val_accuracy: 0.4987\n",
      "Epoch 7/15\n",
      "676/676 [==============================] - 12s 18ms/step - loss: 0.6929 - accuracy: 0.5081 - val_loss: 0.6933 - val_accuracy: 0.4959\n",
      "Epoch 8/15\n",
      "676/676 [==============================] - 12s 18ms/step - loss: 0.6928 - accuracy: 0.5103 - val_loss: 0.6935 - val_accuracy: 0.4970\n",
      "Epoch 9/15\n",
      "676/676 [==============================] - 12s 18ms/step - loss: 0.6928 - accuracy: 0.5073 - val_loss: 0.6932 - val_accuracy: 0.4930\n",
      "Epoch 10/15\n",
      "676/676 [==============================] - 12s 18ms/step - loss: 0.6927 - accuracy: 0.5100 - val_loss: 0.6932 - val_accuracy: 0.4971\n",
      "Epoch 11/15\n",
      "676/676 [==============================] - 10s 14ms/step - loss: 0.6927 - accuracy: 0.5133 - val_loss: 0.6934 - val_accuracy: 0.4963\n",
      "Epoch 12/15\n",
      "676/676 [==============================] - 9s 14ms/step - loss: 0.6926 - accuracy: 0.5160 - val_loss: 0.6937 - val_accuracy: 0.4995\n",
      "Epoch 13/15\n",
      "676/676 [==============================] - 10s 15ms/step - loss: 0.6926 - accuracy: 0.5113 - val_loss: 0.6932 - val_accuracy: 0.4964\n",
      "Epoch 14/15\n",
      "676/676 [==============================] - 9s 14ms/step - loss: 0.6926 - accuracy: 0.5110 - val_loss: 0.6931 - val_accuracy: 0.5014\n",
      "Epoch 15/15\n",
      "676/676 [==============================] - 9s 13ms/step - loss: 0.6926 - accuracy: 0.5133 - val_loss: 0.6933 - val_accuracy: 0.4983\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit(\n",
    "    [user_train, place_train],\n",
    "    y_train,\n",
    "    epochs=15,\n",
    "    batch_size=32,\n",
    "    validation_data=([user_test, place_test], y_test)\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T22:05:17.256436700Z",
     "start_time": "2024-06-17T22:02:47.700993500Z"
    }
   },
   "id": "97dcbacf23c293f3",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def recommend_places(user_id, top_n=5):\n",
    "    user_pref = user_preferences[user_preferences['user_id'] == user_id][place_types].values\n",
    "    place_features = user_place_reviews[place_types].drop_duplicates().values\n",
    "    place_ids = user_place_reviews['id'].drop_duplicates().values\n",
    "\n",
    "    predictions = model.predict([np.repeat(user_pref, len(place_features), axis=0), place_features])\n",
    "    top_indices = np.argsort(predictions[:, 0])[-top_n:][::-1]\n",
    "\n",
    "    recommended_place_ids = place_ids[top_indices]\n",
    "    \n",
    "    # Ensure unique recommendations by using a set\n",
    "    unique_recommendations = set(recommended_place_ids)\n",
    "    \n",
    "    # Retrieve details for unique recommendations\n",
    "    recommended_places = user_place_reviews[user_place_reviews['id'].isin(unique_recommendations)]\n",
    "    sorted_recommendations = recommended_places.sort_values(by='rating', ascending=False)\n",
    "    sorted_recommendations = sorted_recommendations.drop_duplicates(subset=['name'])\n",
    "    \n",
    "    return sorted_recommendations[['name', 'primary-type', 'rating']]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T22:05:17.275075900Z",
     "start_time": "2024-06-17T22:05:17.253392200Z"
    }
   },
   "id": "e568339f08e2789a",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 5ms/step\n",
      "Top Recommendations for User: user_10\n",
      "---------------------------------\n",
      "Name: Melanting waterfall\n",
      "Type: tourist_attraction\n",
      "Rating: 4.7\n",
      "---------------------------------\n",
      "Name: Babi Guling Sunari\n",
      "Type: indonesian_restaurant\n",
      "Rating: 4.5\n",
      "---------------------------------\n",
      "Name: Warung Nyoman\n",
      "Type: indonesian_restaurant\n",
      "Rating: 4.1\n",
      "---------------------------------\n",
      "Name: Mutiara Resto Kintamani\n",
      "Type: restaurant\n",
      "Rating: 4.0\n",
      "---------------------------------\n",
      "Name: Hotel Pancasari\n",
      "Type: hotel\n",
      "Rating: 3.8\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "user_id = 'user_10'\n",
    "recommendations = recommend_places(user_id)\n",
    "\n",
    "print(\"Top Recommendations for User:\", user_id)\n",
    "print(\"---------------------------------\")\n",
    "for index, row in recommendations.iterrows():\n",
    "    print(f\"Name: {row['name']}\")\n",
    "    print(f\"Type: {row['primary-type']}\")\n",
    "    print(f\"Rating: {row['rating']}\")\n",
    "    print(\"---------------------------------\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T22:05:17.949556600Z",
     "start_time": "2024-06-17T22:05:17.262446500Z"
    }
   },
   "id": "b81857a5de03e58d",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.save('user_pref_model.keras')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T22:05:18.193047300Z",
     "start_time": "2024-06-17T22:05:17.944044400Z"
    }
   },
   "id": "92b39d077ea70d3c",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Recommendations for User: user_10\n",
      "---------------------------------\n",
      "Name: Warung Jojo's\n",
      "Type: restaurant\n",
      "Rating: 4.7\n",
      "---------------------------------\n",
      "Name: PAON ALAS\n",
      "Type: restaurant\n",
      "Rating: 4.5\n",
      "---------------------------------\n",
      "Name: Rumah Makan Taman Sari\n",
      "Type: restaurant\n",
      "Rating: 4.3\n",
      "---------------------------------\n",
      "Name: KFC\n",
      "Type: fast_food_restaurant\n",
      "Rating: 4.1\n",
      "---------------------------------\n",
      "Name: Mutiara Resto Kintamani\n",
      "Type: restaurant\n",
      "Rating: 4.0\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to recommend places based on user preferences of types\n",
    "def recommend_places_by_types(user_id, top_n=5):\n",
    "    # Assuming user preferences are one-hot encoded and stored in user_preferences DataFrame\n",
    "    user_pref = user_preferences[user_preferences['user_id'] == user_id][place_types].values\n",
    "    place_features = user_place_reviews[place_types].drop_duplicates().values\n",
    "    place_ids = user_place_reviews['id'].drop_duplicates().values\n",
    "    \n",
    "    # Calculate relevance score based on user preferences and place features\n",
    "    relevance_scores = np.dot(place_features, user_pref.T).flatten()\n",
    "    \n",
    "    # Get indices of top places based on relevance score\n",
    "    top_indices = np.argsort(relevance_scores)[-top_n:][::-1]\n",
    "    \n",
    "    # Get recommended place IDs\n",
    "    recommended_place_ids = place_ids[top_indices]\n",
    "    \n",
    "    # Retrieve details of recommended places\n",
    "    recommended_places = user_place_reviews[user_place_reviews['id'].isin(recommended_place_ids)]\n",
    "    sorted_recommendations = recommended_places.sort_values(by='rating', ascending=False)\n",
    "    sorted_recommendations = sorted_recommendations.drop_duplicates(subset=['name'])\n",
    "    \n",
    "    return sorted_recommendations[['name', 'primary-type', 'rating']]\n",
    "\n",
    "# Example usage\n",
    "user_id = 'user_10'\n",
    "recommendations = recommend_places_by_types(user_id)\n",
    "print(\"Top Recommendations for User:\", user_id)\n",
    "print(\"---------------------------------\")\n",
    "for index, row in recommendations.iterrows():\n",
    "    print(f\"Name: {row['name']}\")\n",
    "    print(f\"Type: {row['primary-type']}\")\n",
    "    print(f\"Rating: {row['rating']}\")\n",
    "    print(\"---------------------------------\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T22:05:18.324615500Z",
     "start_time": "2024-06-17T22:05:18.212307300Z"
    }
   },
   "id": "86da559405c899e0",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 4ms/step\n",
      "Top Recommendations based on Selected Types:\n",
      "---------------------------------\n",
      "Name: BATUR BOAT TOUR AND WATER ACTIVITIES\n",
      "Type: travel_agency\n",
      "Rating: 4.9\n",
      "---------------------------------\n",
      "Name: Air Terjun Umejero\n",
      "Type: tourist_attraction\n",
      "Rating: 4.8\n",
      "---------------------------------\n",
      "Name: Bukit Catu Bungalows\n",
      "Type: hotel\n",
      "Rating: 4.8\n",
      "---------------------------------\n",
      "Name: Sumberkima Hill Retreat\n",
      "Type: resort_hotel\n",
      "Rating: 4.7\n",
      "---------------------------------\n",
      "Name: Studio L\n",
      "Type: hotel\n",
      "Rating: 4.6\n",
      "---------------------------------\n",
      "Name: Air Terjun Tembok Barak\n",
      "Type: tourist_attraction\n",
      "Rating: 4.5\n",
      "---------------------------------\n",
      "Name: Babi Guling Sunari\n",
      "Type: indonesian_restaurant\n",
      "Rating: 4.5\n",
      "---------------------------------\n",
      "Name: KopieNakal Menjangan\n",
      "Type: restaurant\n",
      "Rating: 4.4\n",
      "---------------------------------\n",
      "Name: Lovina Beach\n",
      "Type: tourist_attraction\n",
      "Rating: 4.3\n",
      "---------------------------------\n",
      "Name: Warung Nyoman\n",
      "Type: indonesian_restaurant\n",
      "Rating: 4.1\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Assuming place_features contains one-hot encoded types for each place\n",
    "place_features = user_place_reviews[place_types].drop_duplicates().values\n",
    "place_ids = user_place_reviews['id'].drop_duplicates().values\n",
    "\n",
    "# Convert place_features to a TensorFlow constant\n",
    "place_features_tf = tf.constant(place_features, dtype=tf.float32)\n",
    "\n",
    "# Function to recommend places based on user-selected types using TensorFlow\n",
    "def recommend_places_by_selected_types_tf(selected_types, top_n=5):\n",
    "    # Convert user-selected types into a feature vector\n",
    "    user_input = np.zeros(len(place_types))\n",
    "    for stype in selected_types:\n",
    "        if stype in place_types:\n",
    "            user_input[place_types.index(stype)] = 1\n",
    "    \n",
    "    # Convert user_input to a TensorFlow constant\n",
    "    user_input_tf = tf.constant(user_input.reshape(1, -1), dtype=tf.float32)  # Reshape to (1, len(place_types))\n",
    "    \n",
    "    # Model architecture\n",
    "    input_layer = tf.keras.layers.Input(shape=(len(place_types),))\n",
    "    embeddings = tf.keras.layers.Dense(len(place_types), activation='relu')(input_layer)\n",
    "    similarities = tf.keras.layers.Dot(axes=1, normalize=True)([embeddings, user_input_tf])\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=similarities)\n",
    "    model.compile(optimizer='adam', loss='cosine_similarity')\n",
    "    \n",
    "    # Predict similarity between user input and place features\n",
    "    similarities_pred = model.predict(place_features_tf).flatten()\n",
    "    \n",
    "    # Get indices of top places based on predicted similarities\n",
    "    top_indices = np.argsort(similarities_pred)[-top_n:][::-1]\n",
    "    \n",
    "    # Get recommended place IDs\n",
    "    recommended_place_ids = place_ids[top_indices]\n",
    "    \n",
    "    # Retrieve details of recommended places\n",
    "    recommended_places = user_place_reviews[user_place_reviews['id'].isin(recommended_place_ids)]\n",
    "    sorted_recommendations = recommended_places.sort_values(by='rating', ascending=False)\n",
    "    sorted_recommendations = sorted_recommendations.drop_duplicates(subset=['name'])\n",
    "    \n",
    "    return sorted_recommendations[['name', 'primary-type', 'rating']]\n",
    "\n",
    "# Example usage\n",
    "selected_types = ['hotel', 'restaurant', 'cafe']  # Example user-selected types\n",
    "recommendations = recommend_places_by_selected_types_tf(selected_types, top_n=10)\n",
    "print(\"Top Recommendations based on Selected Types:\")\n",
    "print(\"---------------------------------\")\n",
    "for index, row in recommendations.iterrows():\n",
    "    print(f\"Name: {row['name']}\")\n",
    "    print(f\"Type: {row['primary-type']}\")\n",
    "    print(f\"Rating: {row['rating']}\")\n",
    "    print(\"---------------------------------\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T22:47:58.118480300Z",
     "start_time": "2024-06-17T22:47:57.704355Z"
    }
   },
   "id": "483b7213fed0d5fc",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 5ms/step\n",
      "Top Recommendations based on Selected Types:\n",
      "---------------------------------\n",
      "Name: UmahDeMadya Munduk & Rooftop De Madya Panoramic Restaurant\n",
      "Type: guest_house\n",
      "Rating: 4.9\n",
      "---------------------------------\n",
      "Name: Bukit Mende\n",
      "Type: hindu_temple\n",
      "Rating: 4.9\n",
      "---------------------------------\n",
      "Name: DAPUR PAPA EL\n",
      "Type: cafe\n",
      "Rating: 4.7\n",
      "---------------------------------\n",
      "Name: Gaia-Oasis Beach Resort\n",
      "Type: resort_hotel\n",
      "Rating: 4.7\n",
      "---------------------------------\n",
      "Name: Lanting Paras Resto And Pool... More than just a pool!\n",
      "Type: swimming_pool\n",
      "Rating: 4.6\n",
      "---------------------------------\n",
      "Name: ACK Fried Chicken Udayana\n",
      "Type: fast_food_restaurant\n",
      "Rating: 4.5\n",
      "---------------------------------\n",
      "Name: Warung Barokah\n",
      "Type: indonesian_restaurant\n",
      "Rating: 4.3\n",
      "---------------------------------\n",
      "Name: Sari Hill Bali\n",
      "Type: restaurant\n",
      "Rating: 4.2\n",
      "---------------------------------\n",
      "Name: My Lovina Hotel\n",
      "Type: resort_hotel\n",
      "Rating: 4.2\n",
      "---------------------------------\n",
      "Name: Hotel Singaraja Indah\n",
      "Type: hotel\n",
      "Rating: 3.9\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Assuming place_features contains one-hot encoded types for each place\n",
    "place_features = user_place_reviews[place_types].drop_duplicates().values\n",
    "place_ids = user_place_reviews['id'].drop_duplicates().values\n",
    "\n",
    "# Function to recommend places based on user-selected types using TensorFlow\n",
    "def recommend_places_by_selected_types_tf(selected_types, top_n=5):\n",
    "    # Convert user-selected types into a feature vector\n",
    "    user_input = np.zeros(len(place_types))\n",
    "    for stype in selected_types:\n",
    "        if stype in place_types:\n",
    "            user_input[place_types.index(stype)] = 1\n",
    "    \n",
    "    # Convert user_input to a TensorFlow constant\n",
    "    user_input_tf = tf.constant(user_input.reshape(1, -1), dtype=tf.float32)\n",
    "    \n",
    "    # Model architecture\n",
    "    input_layer = tf.keras.layers.Input(shape=(len(place_types),))\n",
    "    embeddings = tf.keras.layers.Dense(128, activation='relu')(input_layer)\n",
    "    \n",
    "    # User embedding for comparison\n",
    "    user_embedding_layer = tf.keras.layers.Dense(128, activation='relu')(user_input_tf)\n",
    "    \n",
    "    similarities = tf.keras.layers.Dot(axes=-1, normalize=True)([embeddings, user_embedding_layer])\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=similarities)\n",
    "    model.compile(optimizer='adam', loss='cosine_similarity')\n",
    "    \n",
    "    # Predict similarity between user input and place features\n",
    "    similarities_pred = model.predict(place_features).flatten()\n",
    "    \n",
    "    # Get indices of top places based on predicted similarities\n",
    "    top_indices = np.argsort(similarities_pred)[-top_n:][::-1]\n",
    "    \n",
    "    # Get recommended place IDs\n",
    "    recommended_place_ids = place_ids[top_indices]\n",
    "    \n",
    "    # Retrieve details of recommended places\n",
    "    recommended_places = user_place_reviews[user_place_reviews['id'].isin(recommended_place_ids)]\n",
    "    sorted_recommendations = recommended_places.sort_values(by='rating', ascending=False)\n",
    "    sorted_recommendations = sorted_recommendations.drop_duplicates(subset=['name'])\n",
    "    \n",
    "    return sorted_recommendations[['name', 'primary-type', 'rating']]\n",
    "\n",
    "# Example usage\n",
    "selected_types = ['indonesian_restaurant', 'italian_restaurant', 'japanese_restaurant', 'jewelry_store',\n",
    "    'korean_restaurant', 'lebanese_restaurant']  # Example user-selected types\n",
    "recommendations = recommend_places_by_selected_types_tf(selected_types, top_n=10)\n",
    "print(\"Top Recommendations based on Selected Types:\")\n",
    "print(\"---------------------------------\")\n",
    "for index, row in recommendations.iterrows():\n",
    "    print(f\"Name: {row['name']}\")\n",
    "    print(f\"Type: {row['primary-type']}\")\n",
    "    print(f\"Rating: {row['rating']}\")\n",
    "    print(\"---------------------------------\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T22:48:12.224565300Z",
     "start_time": "2024-06-17T22:48:11.773799100Z"
    }
   },
   "id": "e3ff245ce52d6741",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T22:05:18.570833200Z",
     "start_time": "2024-06-17T22:05:18.568831700Z"
    }
   },
   "id": "de624aaaabd17669"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T22:05:18.582967900Z",
     "start_time": "2024-06-17T22:05:18.570833200Z"
    }
   },
   "id": "e2f109aad7b855ff"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a6062e50175b44d6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
