{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38f774bd17046d4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T21:38:14.542151100Z",
     "start_time": "2024-06-17T21:38:13.740225400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                            id                                  types_x  \\\n0  ChIJYcGr7GSb0S0RckePBrCWikw                           hotel, lodging   \n1  ChIJZbWX6Aia0S0R0tM3h1RZ1h8  indonesian_restaurant, restaurant, food   \n2  ChIJYyHbhgia0S0RzdjNXLmcf54     tourist_attraction, restaurant, food   \n3  ChIJ6zf9LJCb0S0RFv3BdLl61ZY           coffee_shop, cafe, food, store   \n4  ChIJ63FmGgaa0S0RWD5dfwhjGHQ  indonesian_restaurant, restaurant, food   \n\n                                              review    user_id  \\\n0  It has quite small room, and the hallway is qu...  user_1828   \n1  Surprisingly, a really good warung that’s hidd...  user_1607   \n2  Only had a fleeting visit here, came by coach,...   user_437   \n3  One word, underrated! How come place like this...  user_2603   \n4  We came here for dinner, food was good, i like...  user_1924   \n\n   sentiment-score                                               name  \\\n0         0.506250  Singaraja Hotel (ex- POP! Hotel Hardys Singara...   \n1         0.606250                                     Warung Bik Juk   \n2         0.491667                   Harbour Tourist Area of Buleleng   \n3         0.672338                                      Abuela Coffee   \n4         0.593056                    Ikan Bakar Tanjung Alam Dermaga   \n\n            primary-type  rating  rating-count  \n0                  hotel     4.1        2581.0  \n1  indonesian_restaurant     4.5         648.0  \n2     tourist_attraction     4.3        2800.0  \n3            coffee_shop     4.9         164.0  \n4  indonesian_restaurant     4.4         138.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>types_x</th>\n      <th>review</th>\n      <th>user_id</th>\n      <th>sentiment-score</th>\n      <th>name</th>\n      <th>primary-type</th>\n      <th>rating</th>\n      <th>rating-count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ChIJYcGr7GSb0S0RckePBrCWikw</td>\n      <td>hotel, lodging</td>\n      <td>It has quite small room, and the hallway is qu...</td>\n      <td>user_1828</td>\n      <td>0.506250</td>\n      <td>Singaraja Hotel (ex- POP! Hotel Hardys Singara...</td>\n      <td>hotel</td>\n      <td>4.1</td>\n      <td>2581.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ChIJZbWX6Aia0S0R0tM3h1RZ1h8</td>\n      <td>indonesian_restaurant, restaurant, food</td>\n      <td>Surprisingly, a really good warung that’s hidd...</td>\n      <td>user_1607</td>\n      <td>0.606250</td>\n      <td>Warung Bik Juk</td>\n      <td>indonesian_restaurant</td>\n      <td>4.5</td>\n      <td>648.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ChIJYyHbhgia0S0RzdjNXLmcf54</td>\n      <td>tourist_attraction, restaurant, food</td>\n      <td>Only had a fleeting visit here, came by coach,...</td>\n      <td>user_437</td>\n      <td>0.491667</td>\n      <td>Harbour Tourist Area of Buleleng</td>\n      <td>tourist_attraction</td>\n      <td>4.3</td>\n      <td>2800.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ChIJ6zf9LJCb0S0RFv3BdLl61ZY</td>\n      <td>coffee_shop, cafe, food, store</td>\n      <td>One word, underrated! How come place like this...</td>\n      <td>user_2603</td>\n      <td>0.672338</td>\n      <td>Abuela Coffee</td>\n      <td>coffee_shop</td>\n      <td>4.9</td>\n      <td>164.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ChIJ63FmGgaa0S0RWD5dfwhjGHQ</td>\n      <td>indonesian_restaurant, restaurant, food</td>\n      <td>We came here for dinner, food was good, i like...</td>\n      <td>user_1924</td>\n      <td>0.593056</td>\n      <td>Ikan Bakar Tanjung Alam Dermaga</td>\n      <td>indonesian_restaurant</td>\n      <td>4.4</td>\n      <td>138.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "places_data = pd.read_csv(\"final-dataset/main_dataset.csv\") \n",
    "reviews_data = pd.read_csv(\"final-dataset/review_dataset.csv\")  \n",
    "\n",
    "user_place_reviews = pd.merge(reviews_data,places_data, on='id')\n",
    "\n",
    "# drop review_number, lat long, address, url,status, phone, types_y, price-level,review 1-5\n",
    "user_place_reviews = user_place_reviews.drop(columns=['review_number', 'latitude', 'longitude', 'address', 'url', 'status', 'phone', 'types_y', 'price-level', 'review 1', 'review 2', 'review 3', 'review 4', 'review 5'])\n",
    "user_place_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                            id  \\\n0  ChIJYcGr7GSb0S0RckePBrCWikw   \n1  ChIJZbWX6Aia0S0R0tM3h1RZ1h8   \n2  ChIJYyHbhgia0S0RzdjNXLmcf54   \n3  ChIJ6zf9LJCb0S0RFv3BdLl61ZY   \n4  ChIJ63FmGgaa0S0RWD5dfwhjGHQ   \n\n                                              review    user_id  \\\n0  It has quite small room, and the hallway is qu...  user_1828   \n1  Surprisingly, a really good warung that’s hidd...  user_1607   \n2  Only had a fleeting visit here, came by coach,...   user_437   \n3  One word, underrated! How come place like this...  user_2603   \n4  We came here for dinner, food was good, i like...  user_1924   \n\n   sentiment-score                                               name  \\\n0         0.506250  Singaraja Hotel (ex- POP! Hotel Hardys Singara...   \n1         0.606250                                     Warung Bik Juk   \n2         0.491667                   Harbour Tourist Area of Buleleng   \n3         0.672338                                      Abuela Coffee   \n4         0.593056                    Ikan Bakar Tanjung Alam Dermaga   \n\n            primary-type  rating  rating-count  airport  american_restaurant  \\\n0                  hotel     4.1        2581.0        0                    0   \n1  indonesian_restaurant     4.5         648.0        0                    0   \n2     tourist_attraction     4.3        2800.0        0                    0   \n3            coffee_shop     4.9         164.0        0                    0   \n4  indonesian_restaurant     4.4         138.0        0                    0   \n\n   ...  tourist_attraction  travel_agency  turkish_restaurant  university  \\\n0  ...                   0              0                   0           0   \n1  ...                   0              0                   0           0   \n2  ...                   1              0                   0           0   \n3  ...                   0              0                   0           0   \n4  ...                   0              0                   0           0   \n\n   vegan_restaurant  vegetarian_restaurant  vietnamese_restaurant  \\\n0                 0                      0                      0   \n1                 0                      0                      0   \n2                 0                      0                      0   \n3                 0                      0                      0   \n4                 0                      0                      0   \n\n   wedding_venue  wholesaler  zoo  \n0              0           0    0  \n1              0           0    0  \n2              0           0    0  \n3              0           0    0  \n4              0           0    0  \n\n[5 rows x 133 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>review</th>\n      <th>user_id</th>\n      <th>sentiment-score</th>\n      <th>name</th>\n      <th>primary-type</th>\n      <th>rating</th>\n      <th>rating-count</th>\n      <th>airport</th>\n      <th>american_restaurant</th>\n      <th>...</th>\n      <th>tourist_attraction</th>\n      <th>travel_agency</th>\n      <th>turkish_restaurant</th>\n      <th>university</th>\n      <th>vegan_restaurant</th>\n      <th>vegetarian_restaurant</th>\n      <th>vietnamese_restaurant</th>\n      <th>wedding_venue</th>\n      <th>wholesaler</th>\n      <th>zoo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ChIJYcGr7GSb0S0RckePBrCWikw</td>\n      <td>It has quite small room, and the hallway is qu...</td>\n      <td>user_1828</td>\n      <td>0.506250</td>\n      <td>Singaraja Hotel (ex- POP! Hotel Hardys Singara...</td>\n      <td>hotel</td>\n      <td>4.1</td>\n      <td>2581.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ChIJZbWX6Aia0S0R0tM3h1RZ1h8</td>\n      <td>Surprisingly, a really good warung that’s hidd...</td>\n      <td>user_1607</td>\n      <td>0.606250</td>\n      <td>Warung Bik Juk</td>\n      <td>indonesian_restaurant</td>\n      <td>4.5</td>\n      <td>648.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ChIJYyHbhgia0S0RzdjNXLmcf54</td>\n      <td>Only had a fleeting visit here, came by coach,...</td>\n      <td>user_437</td>\n      <td>0.491667</td>\n      <td>Harbour Tourist Area of Buleleng</td>\n      <td>tourist_attraction</td>\n      <td>4.3</td>\n      <td>2800.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ChIJ6zf9LJCb0S0RFv3BdLl61ZY</td>\n      <td>One word, underrated! How come place like this...</td>\n      <td>user_2603</td>\n      <td>0.672338</td>\n      <td>Abuela Coffee</td>\n      <td>coffee_shop</td>\n      <td>4.9</td>\n      <td>164.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ChIJ63FmGgaa0S0RWD5dfwhjGHQ</td>\n      <td>We came here for dinner, food was good, i like...</td>\n      <td>user_1924</td>\n      <td>0.593056</td>\n      <td>Ikan Bakar Tanjung Alam Dermaga</td>\n      <td>indonesian_restaurant</td>\n      <td>4.4</td>\n      <td>138.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 133 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "user_place_reviews['types_x'] = user_place_reviews['types_x'].str.split(', ')\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "one_hot = mlb.fit_transform(user_place_reviews['types_x'])\n",
    "\n",
    "one_hot_df = pd.DataFrame(one_hot, columns=mlb.classes_)\n",
    "\n",
    "user_place_reviews = pd.concat([user_place_reviews, one_hot_df], axis=1)\n",
    "\n",
    "user_place_reviews = user_place_reviews.drop_duplicates(subset=['user_id', 'id'])\n",
    "\n",
    "user_place_reviews = user_place_reviews.drop(columns=['types_x'])\n",
    "\n",
    "user_place_reviews.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T21:38:14.695629500Z",
     "start_time": "2024-06-17T21:38:14.550698300Z"
    }
   },
   "id": "bee4dde90012a62c",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "        user_id  airport  american_restaurant  amusement_center  \\\n0        user_1      0.0                  0.0               0.0   \n1       user_10      0.0                  0.0               0.0   \n2      user_100      0.0                  0.0               0.0   \n3     user_1000      0.0                  0.0               0.0   \n4     user_1001      0.0                  0.0               0.0   \n...         ...      ...                  ...               ...   \n2679   user_995      0.0                  0.0               0.0   \n2680   user_996      0.0                  0.0               0.0   \n2681   user_997      0.0                  0.0               0.0   \n2682   user_998      0.0                  0.0               0.0   \n2683   user_999      0.0                  0.0               0.0   \n\n      amusement_park  art_gallery  athletic_field  atm    bakery  \\\n0                0.0          0.0             0.0  0.0  0.000000   \n1                0.0          0.0             0.0  0.0  0.000000   \n2                0.0          0.0             0.0  0.0  0.000000   \n3                0.0          0.0             0.0  0.0  0.058824   \n4                0.0          0.0             0.0  0.0  0.000000   \n...              ...          ...             ...  ...       ...   \n2679             0.0          0.0             0.0  0.0  0.000000   \n2680             0.0          0.0             0.0  0.0  0.045455   \n2681             0.0          0.0             0.0  0.0  0.000000   \n2682             0.0          0.0             0.0  0.0  0.000000   \n2683             0.0          0.0             0.0  0.0  0.000000   \n\n      banquet_hall  ...  tourist_attraction  travel_agency  \\\n0              0.0  ...            0.000000            0.0   \n1              0.0  ...            0.058824            0.0   \n2              0.0  ...            0.000000            0.0   \n3              0.0  ...            0.058824            0.0   \n4              0.0  ...            0.000000            0.0   \n...            ...  ...                 ...            ...   \n2679           0.0  ...            0.000000            0.0   \n2680           0.0  ...            0.000000            0.0   \n2681           0.0  ...            0.000000            0.0   \n2682           0.0  ...            0.000000            0.0   \n2683           0.0  ...            0.000000            0.0   \n\n      turkish_restaurant  university  vegan_restaurant  vegetarian_restaurant  \\\n0                    0.0         0.0          0.000000               0.000000   \n1                    0.0         0.0          0.000000               0.000000   \n2                    0.0         0.0          0.000000               0.000000   \n3                    0.0         0.0          0.058824               0.058824   \n4                    0.0         0.0          0.000000               0.000000   \n...                  ...         ...               ...                    ...   \n2679                 0.0         0.0          0.000000               0.000000   \n2680                 0.0         0.0          0.000000               0.000000   \n2681                 0.0         0.0          0.000000               0.000000   \n2682                 0.0         0.0          0.000000               0.000000   \n2683                 0.0         0.0          0.000000               0.000000   \n\n      vietnamese_restaurant  wedding_venue  wholesaler  zoo  \n0                       0.0       0.000000    0.000000  0.0  \n1                       0.0       0.000000    0.000000  0.0  \n2                       0.0       0.000000    0.000000  0.0  \n3                       0.0       0.000000    0.058824  0.0  \n4                       0.0       0.000000    0.000000  0.0  \n...                     ...            ...         ...  ...  \n2679                    0.0       0.028571    0.000000  0.0  \n2680                    0.0       0.000000    0.045455  0.0  \n2681                    0.0       0.000000    0.000000  0.0  \n2682                    0.0       0.000000    0.000000  0.0  \n2683                    0.0       0.000000    0.000000  0.0  \n\n[2684 rows x 126 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>airport</th>\n      <th>american_restaurant</th>\n      <th>amusement_center</th>\n      <th>amusement_park</th>\n      <th>art_gallery</th>\n      <th>athletic_field</th>\n      <th>atm</th>\n      <th>bakery</th>\n      <th>banquet_hall</th>\n      <th>...</th>\n      <th>tourist_attraction</th>\n      <th>travel_agency</th>\n      <th>turkish_restaurant</th>\n      <th>university</th>\n      <th>vegan_restaurant</th>\n      <th>vegetarian_restaurant</th>\n      <th>vietnamese_restaurant</th>\n      <th>wedding_venue</th>\n      <th>wholesaler</th>\n      <th>zoo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>user_1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>user_10</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.058824</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>user_100</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>user_1000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.058824</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.058824</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.058824</td>\n      <td>0.058824</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.058824</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>user_1001</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2679</th>\n      <td>user_995</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.028571</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2680</th>\n      <td>user_996</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.045455</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.045455</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2681</th>\n      <td>user_997</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2682</th>\n      <td>user_998</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2683</th>\n      <td>user_999</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2684 rows × 126 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# List of place type columns\n",
    "place_types = [\n",
    "    'airport', 'american_restaurant', 'amusement_center', 'amusement_park', 'art_gallery',\n",
    "    'athletic_field', 'atm', 'bakery', 'banquet_hall', 'bar', 'barbecue_restaurant',\n",
    "    'barber_shop', 'beauty_salon', 'bed_and_breakfast', 'bicycle_store', 'brazilian_restaurant',\n",
    "    'breakfast_restaurant', 'brunch_restaurant', 'cafe', 'campground', 'camping_cabin',\n",
    "    'car_rental', 'car_wash', 'cemetery', 'child_care_agency', 'chinese_restaurant', 'church',\n",
    "    'clothing_store', 'coffee_shop', 'community_center', 'consultant', 'convention_center', 'cottage',\n",
    "    'cultural_center', 'dog_park', 'event_venue', 'extended_stay_hotel', 'farm', 'farmstay',\n",
    "    'fast_food_restaurant', 'finance', 'fitness_center', 'florist', 'food', 'french_restaurant',\n",
    "    'furniture_store', 'general_contractor', 'gift_shop', 'golf_course', 'greek_restaurant',\n",
    "    'grocery_store', 'guest_house', 'gym', 'hair_care', 'hair_salon', 'hamburger_restaurant',\n",
    "    'health', 'heliport', 'hiking_area', 'hindu_temple', 'historical_landmark', 'home_goods_store',\n",
    "    'home_improvement_store', 'hostel', 'hotel', 'ice_cream_shop', 'indian_restaurant',\n",
    "    'indonesian_restaurant', 'italian_restaurant', 'japanese_restaurant', 'jewelry_store',\n",
    "    'korean_restaurant', 'lebanese_restaurant', 'library', 'liquor_store', 'lodging', 'market',\n",
    "    'meal_delivery', 'meal_takeaway', 'mediterranean_restaurant', 'mexican_restaurant',\n",
    "    'middle_eastern_restaurant', 'mosque', 'motel', 'movie_theater', 'museum', 'national_park',\n",
    "    'night_club', 'park', 'performing_arts_theater', 'pizza_restaurant',\n",
    "    'place_of_worship', 'playground', 'preschool', 'private_guest_room', 'ramen_restaurant',\n",
    "    'real_estate_agency', 'resort_hotel', 'rest_stop', 'restaurant', 'sandwich_shop', 'school',\n",
    "    'seafood_restaurant', 'shopping_mall', 'spa', 'spanish_restaurant', 'sporting_goods_store',\n",
    "    'sports_club', 'sports_complex', 'steak_house', 'store', 'supermarket', 'sushi_restaurant',\n",
    "    'swimming_pool', 'thai_restaurant', 'tourist_attraction', 'travel_agency', 'turkish_restaurant',\n",
    "    'university', 'vegan_restaurant', 'vegetarian_restaurant', 'vietnamese_restaurant',\n",
    "    'wedding_venue', 'wholesaler', 'zoo'\n",
    "]\n",
    "\n",
    "# Sum the place type columns for each user to get their preferences\n",
    "user_preferences = user_place_reviews.groupby('user_id')[place_types].sum().reset_index()\n",
    "\n",
    "# Normalize the preferences\n",
    "user_preferences[place_types] = user_preferences[place_types].div(user_preferences[place_types].sum(axis=1), axis=0)\n",
    "\n",
    "user_preferences\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T21:38:14.803559300Z",
     "start_time": "2024-06-17T21:38:14.689572Z"
    }
   },
   "id": "8c5e21af968d9aff",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " user_input (InputLayer)     [(None, 125)]                0         []                            \n",
      "                                                                                                  \n",
      " place_input (InputLayer)    [(None, 125)]                0         []                            \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 50)                   6300      ['user_input[0][0]']          \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 50)                   6300      ['place_input[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 100)                  0         ['dense_5[0][0]',             \n",
      " )                                                                   'dense_6[0][0]']             \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 128)                  12928     ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 64)                   8256      ['dense_7[0][0]']             \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 1)                    65        ['dense_8[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 33849 (132.22 KB)\n",
      "Trainable params: 33849 (132.22 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "\n",
    "# Hyperparameters\n",
    "embedding_dim = 50\n",
    "\n",
    "# User model\n",
    "user_input = Input(shape=(len(place_types),), name='user_input')\n",
    "user_embedding = Dense(embedding_dim, activation='relu')(user_input)\n",
    "\n",
    "# Place model\n",
    "place_input = Input(shape=(len(place_types),), name='place_input')\n",
    "place_embedding = Dense(embedding_dim, activation='relu')(place_input)\n",
    "\n",
    "# Concatenate user and place embeddings\n",
    "merged = Concatenate()([user_embedding, place_embedding])\n",
    "dense_1 = Dense(128, activation='relu')(merged)\n",
    "dense_2 = Dense(64, activation='relu')(dense_1)\n",
    "output = Dense(1, activation='sigmoid')(dense_2)\n",
    "\n",
    "# Create and compile the model\n",
    "model = Model(inputs=[user_input, place_input], outputs=output)\n",
    "model.compile(optimizer='SGD', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T21:38:14.933259Z",
     "start_time": "2024-06-17T21:38:14.761743900Z"
    }
   },
   "id": "7b318c87d1f7f1a0",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Ensure user_preferences and data are correctly aligned and split the data accordingly\n",
    "user_preferences = user_place_reviews.groupby('user_id')[place_types].sum().reset_index()\n",
    "user_preferences[place_types] = user_preferences[place_types].div(user_preferences[place_types].sum(axis=1), axis=0)\n",
    "\n",
    "# Merge data with user preferences to align place features with user preferences\n",
    "merged_data = user_place_reviews.merge(user_preferences, on='user_id', suffixes=('', '_user'))\n",
    "\n",
    "# Prepare user features and place features for each review\n",
    "user_features = merged_data[[f'{ptype}_user' for ptype in place_types]].values\n",
    "place_features = merged_data[place_types].values\n",
    "\n",
    "# Generate labels (assuming binary relevance for simplicity)\n",
    "# You need to ensure your labels are the same length as user and place features\n",
    "labels = np.random.randint(2, size=(len(user_features),))\n",
    "\n",
    "# Split into train and test sets ensuring the lengths match\n",
    "user_train, user_test, place_train, place_test, y_train, y_test = train_test_split(\n",
    "    user_features, place_features, labels, test_size=0.3, random_state=42\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T21:38:15.092646100Z",
     "start_time": "2024-06-17T21:38:14.878450Z"
    }
   },
   "id": "3bc2972329ebb950",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "587/587 [==============================] - 8s 12ms/step - loss: 0.6932 - accuracy: 0.5029 - val_loss: 0.6932 - val_accuracy: 0.5076\n",
      "Epoch 2/15\n",
      "587/587 [==============================] - 6s 11ms/step - loss: 0.6932 - accuracy: 0.4993 - val_loss: 0.6931 - val_accuracy: 0.5079\n",
      "Epoch 3/15\n",
      "587/587 [==============================] - 6s 10ms/step - loss: 0.6931 - accuracy: 0.5058 - val_loss: 0.6931 - val_accuracy: 0.5065\n",
      "Epoch 4/15\n",
      "587/587 [==============================] - 6s 10ms/step - loss: 0.6930 - accuracy: 0.5042 - val_loss: 0.6931 - val_accuracy: 0.5068\n",
      "Epoch 5/15\n",
      "587/587 [==============================] - 6s 10ms/step - loss: 0.6930 - accuracy: 0.5039 - val_loss: 0.6931 - val_accuracy: 0.5069\n",
      "Epoch 6/15\n",
      "587/587 [==============================] - 6s 10ms/step - loss: 0.6929 - accuracy: 0.5110 - val_loss: 0.6931 - val_accuracy: 0.5119\n",
      "Epoch 7/15\n",
      "587/587 [==============================] - 6s 10ms/step - loss: 0.6929 - accuracy: 0.5088 - val_loss: 0.6931 - val_accuracy: 0.5111\n",
      "Epoch 8/15\n",
      "587/587 [==============================] - 6s 10ms/step - loss: 0.6928 - accuracy: 0.5099 - val_loss: 0.6931 - val_accuracy: 0.5049\n",
      "Epoch 9/15\n",
      "587/587 [==============================] - 6s 10ms/step - loss: 0.6928 - accuracy: 0.5091 - val_loss: 0.6931 - val_accuracy: 0.5078\n",
      "Epoch 10/15\n",
      "587/587 [==============================] - 6s 10ms/step - loss: 0.6928 - accuracy: 0.5128 - val_loss: 0.6931 - val_accuracy: 0.5038\n",
      "Epoch 11/15\n",
      "587/587 [==============================] - 6s 10ms/step - loss: 0.6928 - accuracy: 0.5101 - val_loss: 0.6931 - val_accuracy: 0.5055\n",
      "Epoch 12/15\n",
      "587/587 [==============================] - 6s 10ms/step - loss: 0.6927 - accuracy: 0.5114 - val_loss: 0.6931 - val_accuracy: 0.5086\n",
      "Epoch 13/15\n",
      "587/587 [==============================] - 6s 10ms/step - loss: 0.6926 - accuracy: 0.5152 - val_loss: 0.6932 - val_accuracy: 0.5065\n",
      "Epoch 14/15\n",
      "587/587 [==============================] - 6s 10ms/step - loss: 0.6927 - accuracy: 0.5119 - val_loss: 0.6931 - val_accuracy: 0.5084\n",
      "Epoch 15/15\n",
      "587/587 [==============================] - 6s 10ms/step - loss: 0.6926 - accuracy: 0.5136 - val_loss: 0.6932 - val_accuracy: 0.5131\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit(\n",
    "    [user_train, place_train],\n",
    "    y_train,\n",
    "    epochs=15,\n",
    "    batch_size=32,\n",
    "    validation_data=([user_test, place_test], y_test)\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T21:39:46.771772800Z",
     "start_time": "2024-06-17T21:38:15.088352300Z"
    }
   },
   "id": "97dcbacf23c293f3",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def recommend_places(user_id, top_n=5):\n",
    "    user_pref = user_preferences[user_preferences['user_id'] == user_id][place_types].values\n",
    "    place_features = user_place_reviews[place_types].drop_duplicates().values\n",
    "    place_ids = user_place_reviews['id'].drop_duplicates().values\n",
    "\n",
    "    predictions = model.predict([np.repeat(user_pref, len(place_features), axis=0), place_features])\n",
    "    top_indices = np.argsort(predictions[:, 0])[-top_n:][::-1]\n",
    "\n",
    "    recommended_place_ids = place_ids[top_indices]\n",
    "    \n",
    "    # Ensure unique recommendations by using a set\n",
    "    unique_recommendations = set(recommended_place_ids)\n",
    "    \n",
    "    # Retrieve details for unique recommendations\n",
    "    recommended_places = user_place_reviews[user_place_reviews['id'].isin(unique_recommendations)]\n",
    "    sorted_recommendations = recommended_places.sort_values(by='rating', ascending=False)\n",
    "    sorted_recommendations = sorted_recommendations.drop_duplicates(subset=['name'])\n",
    "    \n",
    "    return sorted_recommendations[['name', 'primary-type', 'rating']]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T21:39:46.778483500Z",
     "start_time": "2024-06-17T21:39:46.771772800Z"
    }
   },
   "id": "e568339f08e2789a",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 4ms/step\n",
      "Top Recommendations for User: user_10\n",
      "---------------------------------\n",
      "Name: The Lost cafe\n",
      "Type: cafe\n",
      "Rating: 4.9\n",
      "---------------------------------\n",
      "Name: Gusto Resto & Cafe\n",
      "Type: pizza_restaurant\n",
      "Rating: 4.8\n",
      "---------------------------------\n",
      "Name: Alami Resort & Restaurant\n",
      "Type: hotel\n",
      "Rating: 4.7\n",
      "---------------------------------\n",
      "Name: REJENG BALI\n",
      "Type: indonesian_restaurant\n",
      "Rating: 4.6\n",
      "---------------------------------\n",
      "Name: D'Kailash Retreat\n",
      "Type: hotel\n",
      "Rating: 4.6\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "user_id = 'user_10'\n",
    "recommendations = recommend_places(user_id)\n",
    "\n",
    "print(\"Top Recommendations for User:\", user_id)\n",
    "print(\"---------------------------------\")\n",
    "for index, row in recommendations.iterrows():\n",
    "    print(f\"Name: {row['name']}\")\n",
    "    print(f\"Type: {row['primary-type']}\")\n",
    "    print(f\"Rating: {row['rating']}\")\n",
    "    print(\"---------------------------------\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T21:41:00.033410800Z",
     "start_time": "2024-06-17T21:40:59.765454200Z"
    }
   },
   "id": "b81857a5de03e58d",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.save('user_pref_model.keras')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T21:45:00.244784Z",
     "start_time": "2024-06-17T21:45:00.137619900Z"
    }
   },
   "id": "92b39d077ea70d3c",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T21:39:47.067370400Z",
     "start_time": "2024-06-17T21:39:47.054293Z"
    }
   },
   "id": "86da559405c899e0",
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
