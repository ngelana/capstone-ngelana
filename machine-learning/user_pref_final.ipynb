{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Constants\n",
    "PLACE_TYPES = [\n",
    "    \"car_rental\", \"art_gallery\", \"museum\", \"performing_arts_theater\", \"hiking_area\",\n",
    "    \"national_park\", \"night_club\", \"park\", \"tourist_attraction\", \"zoo\",\n",
    "    \"american_restaurant\", \"bar\", \"barbecue_restaurant\", \"cafe\", \"chinese_restaurant\",\n",
    "    \"coffee_shop\", \"fast_food_restaurant\", \"french_restaurant\", \"greek_restaurant\",\n",
    "    \"indian_restaurant\", \"indonesian_restaurant\", \"italian_restaurant\",\n",
    "    \"japanese_restaurant\", \"korean_restaurant\", \"lebanese_restaurant\",\n",
    "    \"mediterranean_restaurant\", \"mexican_restaurant\", \"middle_eastern_restaurant\",\n",
    "    \"restaurant\", \"seafood_restaurant\", \"spanish_restaurant\", \"steak_house\",\n",
    "    \"sushi_restaurant\", \"thai_restaurant\", \"turkish_restaurant\", \"vietnamese_restaurant\",\n",
    "    \"cottage\", \"guest_house\", \"hostel\", \"hotel\", \"lodging\", \"motel\", \"private_guest_room\",\n",
    "    \"resort_hotel\"\n",
    "]"
   ],
   "id": "86674b69bcdc71aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Function to load and preprocess data\n",
    "def load_and_preprocess_data():\n",
    "    places_data = pd.read_csv(\"final-dataset/dataset_main.csv\")\n",
    "    reviews_data = pd.read_csv(\"final-dataset/dataset_reviews.csv\")\n",
    "\n",
    "    # Merge datasets on 'id'\n",
    "    user_place_reviews = pd.merge(reviews_data, places_data, on='id')\n",
    "\n",
    "    # Drop irrelevant columns\n",
    "    user_place_reviews = user_place_reviews.drop(columns=[\n",
    "        'review_number', 'latitude', 'longitude', 'address', 'url', 'status', 'phone',\n",
    "        'types_y', 'price-level', 'review 1', 'review 2', 'review 3', 'review 4', 'review 5'\n",
    "    ])\n",
    "\n",
    "    # Split 'types_x' into multiple types\n",
    "    user_place_reviews['types_x'] = user_place_reviews['types_x'].str.split(', ')\n",
    "\n",
    "    # One-hot encode 'types_x'\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    one_hot = mlb.fit_transform(user_place_reviews['types_x'])\n",
    "    one_hot_df = pd.DataFrame(one_hot, columns=mlb.classes_)\n",
    "    user_place_reviews = pd.concat([user_place_reviews, one_hot_df], axis=1)\n",
    "\n",
    "    # Remove duplicates\n",
    "    user_place_reviews = user_place_reviews.drop_duplicates(subset=['user_id', 'id'])\n",
    "\n",
    "    # Compute user preferences\n",
    "    user_preferences = user_place_reviews.groupby('user_id')[PLACE_TYPES].sum().reset_index()\n",
    "    user_preferences[PLACE_TYPES] = user_preferences[PLACE_TYPES].div(\n",
    "        user_preferences[PLACE_TYPES].sum(axis=1), axis=0\n",
    "    )\n",
    "    user_preferences[PLACE_TYPES] = user_preferences[PLACE_TYPES].applymap(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    user_place_reviews.to_csv('other-dataset/place_reviews.csv', index=False)\n",
    "    user_preferences.to_csv('other-dataset/user_preferences.csv', index=False)\n",
    "\n",
    "    return user_place_reviews, user_preferences"
   ],
   "id": "662e1ee6b7d03084",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_model(input_dim, embedding_dim=50):\n",
    "    # User model\n",
    "    user_input = Input(shape=(input_dim,), name='user_input')\n",
    "    user_embedding = Dense(embedding_dim, activation='relu')(user_input)\n",
    "\n",
    "    # Place model\n",
    "    place_input = Input(shape=(input_dim,), name='place_input')\n",
    "    place_embedding = Dense(embedding_dim, activation='relu')(place_input)\n",
    "\n",
    "    # Concatenate embeddings\n",
    "    merged = Concatenate()([user_embedding, place_embedding])\n",
    "    dense_1 = Dense(128, activation='relu')(merged)\n",
    "    dense_2 = Dense(64, activation='relu')(dense_1)\n",
    "    output = Dense(1, activation='sigmoid')(dense_2)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs=[user_input, place_input], outputs=output)\n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ],
   "id": "7107de4e5144ebb2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Function to recommend places\n",
    "def recommend_places(model, user_preferences, user_place_reviews, selected_types, scaler, user_id=None, top_n=20):\n",
    "    # Get user preferences\n",
    "    if user_id:\n",
    "        user_pref = user_preferences[user_preferences['user_id'] == user_id][PLACE_TYPES].values\n",
    "    else:\n",
    "        user_pref = np.random.randint(2, size=(1, len(PLACE_TYPES)))\n",
    "\n",
    "    # Filter places by selected types\n",
    "    filtered_places = user_place_reviews[user_place_reviews[selected_types].any(axis=1)]\n",
    "\n",
    "    place_features = filtered_places[PLACE_TYPES].drop_duplicates().values\n",
    "    place_ids = filtered_places['id'].drop_duplicates().values\n",
    "\n",
    "    place_features_scaled = scaler.transform(place_features)\n",
    "    user_pref_scaled = scaler.transform(np.repeat(user_pref, len(place_features), axis=0))\n",
    "\n",
    "    predictions = model.predict([user_pref_scaled, place_features_scaled])\n",
    "\n",
    "    top_indices = np.argsort(predictions[:, 0])[-top_n:][::-1]\n",
    "    recommended_place_ids = place_ids[top_indices]\n",
    "\n",
    "    unique_recommendations = set(recommended_place_ids)\n",
    "    recommended_places = filtered_places[filtered_places['id'].isin(unique_recommendations)]\n",
    "    sorted_recommendations = recommended_places.sort_values(by='rating', ascending=False)\n",
    "    sorted_recommendations = sorted_recommendations.drop_duplicates(subset=['name'])\n",
    "\n",
    "    return sorted_recommendations[['name', 'primary-type', 'rating']]"
   ],
   "id": "c440dbb560460f6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Main execution\n",
    "def main():\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    # Load and preprocess data\n",
    "    user_place_reviews, user_preferences = load_and_preprocess_data()\n",
    "\n",
    "    # Merge data with user preferences\n",
    "    merged_data = user_place_reviews.merge(user_preferences, on='user_id', suffixes=('', '_user'))\n",
    "    \n",
    "    merged_data.to_csv('other-dataset/merged_data.csv', index=False)\n",
    "\n",
    "    # Prepare features\n",
    "    user_features = merged_data[[f'{ptype}_user' for ptype in PLACE_TYPES]].values\n",
    "    place_features = merged_data[PLACE_TYPES].values\n",
    "\n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    user_features_scaled = scaler.fit_transform(user_features)\n",
    "    place_features_scaled = scaler.fit_transform(place_features)\n",
    "\n",
    "    # Generate labels\n",
    "    labels = np.random.randint(2, size=(len(user_features),))\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    user_train, user_test, place_train, place_test, y_train, y_test = train_test_split(\n",
    "        user_features_scaled, place_features_scaled, labels, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    # Create and train the model\n",
    "    model = create_model(input_dim=len(PLACE_TYPES))\n",
    "    model.summary()\n",
    "\n",
    "    history = model.fit(\n",
    "        [user_train, place_train], y_train,\n",
    "        epochs=15, batch_size=32,\n",
    "        validation_data=([user_test, place_test], y_test)\n",
    "    )\n",
    "\n",
    "    # Save the model\n",
    "    # model.save('user_pref_model.keras')\n",
    "\n",
    "    # Make recommendations\n",
    "    random_user = user_place_reviews['user_id'].sample(1).values[0]\n",
    "    selected_types = ['hotel', 'lodging']\n",
    "\n",
    "    recommendations = recommend_places(model, user_preferences, user_place_reviews, selected_types, scaler, user_id=random_user, top_n=5)\n",
    "    model.save('other-dataset/user_pref.keras')\n",
    "\n",
    "    print(f\"Top Recommendations for user {random_user}:\")\n",
    "    print(recommendations)"
   ],
   "id": "8df3024aaf3bdced",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "e5eb7dad2b77a59f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d47684026ae9129c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
