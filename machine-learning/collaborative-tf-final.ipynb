{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Import libraries used for collaborative filtering\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense, Input, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad95477db1308f27",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('combined-dataset/final_reviews_dataV2.csv')\n",
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df817ae75648f1bc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import hashlib\n",
    "import time\n",
    "\n",
    "def generate_cuid():\n",
    "    c = 'c'\n",
    "    timestamp_str = ''.join(random.choices(string.ascii_lowercase + string.digits, k=8))  # Random 8 char string for timestamp\n",
    "    counter = random.randint(0, 9999)  # Random counter\n",
    "    client_fingerprint = ''.join(random.choices(string.ascii_lowercase + string.digits, k=4))  # Random 4 char string\n",
    "    random_string = ''.join(random.choices(string.ascii_lowercase + string.digits, k=8))  # Random 8 char string\n",
    "\n",
    "    return f'{c}{timestamp_str}{counter}{client_fingerprint}{random_string}'\n",
    "\n",
    "unique_user_ids = df['user_id'].unique()\n",
    "user_id_to_cuid = {user_id: generate_cuid() for user_id in unique_user_ids}\n",
    "\n",
    "# Replace original user IDs with CUIDs\n",
    "df['user_cuid'] = df['user_id'].map(user_id_to_cuid)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e16ba6a0994fccd2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# Encode the place types and place ids\n",
    "type_encoder = LabelEncoder()\n",
    "df['types_encoded'] = type_encoder.fit_transform(df['types'])\n",
    "\n",
    "place_encoder = LabelEncoder()\n",
    "df['place_id_encoded'] = place_encoder.fit_transform(df['id'])\n",
    "\n",
    "# Prepare the dataset\n",
    "X = df[['types_encoded', 'review']].copy()\n",
    "y = df['place_id_encoded'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the model\n",
    "class RecommenderModel(tf.keras.Model):\n",
    "    def __init__(self, num_places, num_types, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.type_embedding = tf.keras.layers.Embedding(num_types, embedding_dim)\n",
    "        self.review_vectorizer = tf.keras.layers.TextVectorization(max_tokens=10000, output_mode='tf_idf')\n",
    "        self.dense = tf.keras.layers.Dense(128, activation='relu')\n",
    "        self.output_layer = tf.keras.layers.Dense(num_places, activation='softmax')\n",
    "        self.review_vectorizer.adapt(X_train['review'])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        type_embedding = self.type_embedding(inputs['types_encoded'])\n",
    "        review_embedding = self.review_vectorizer(inputs['review'])\n",
    "        x = tf.concat([type_embedding, review_embedding], axis=1)\n",
    "        x = self.dense(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "# Initialize the model\n",
    "num_places = df['place_id_encoded'].nunique()\n",
    "num_types = df['types_encoded'].nunique()\n",
    "embedding_dim = 50\n",
    "\n",
    "model = RecommenderModel(num_places, num_types, embedding_dim)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create a custom data generator\n",
    "def data_generator(X, y, batch_size=2):\n",
    "    num_samples = len(X)\n",
    "    while True:\n",
    "        indices = np.arange(num_samples)\n",
    "        np.random.shuffle(indices)\n",
    "        for start in range(0, num_samples, batch_size):\n",
    "            end = min(start + batch_size, num_samples)\n",
    "            batch_indices = indices[start:end]\n",
    "            batch_X = {\n",
    "                'types_encoded': np.array(X.iloc[batch_indices]['types_encoded']),\n",
    "                'review': np.array(X.iloc[batch_indices]['review'])\n",
    "            }\n",
    "            batch_y = np.array(y[batch_indices])\n",
    "            yield batch_X, batch_y\n",
    "\n",
    "# Train the model\n",
    "train_gen = data_generator(X_train, y_train)\n",
    "test_gen = data_generator(X_test, y_test)\n",
    "\n",
    "model.fit(train_gen, steps_per_epoch=len(X_train) // 2, epochs=10, validation_data=test_gen, validation_steps=len(X_test) // 2)\n",
    "\n",
    "# Make recommendations\n",
    "def recommend(user_cuid, model, df, place_encoder, type_encoder):\n",
    "    user_reviews = df[df['user_cuid'] == user_cuid]['review'].values\n",
    "    user_types = df[df['user_cuid'] == user_cuid]['types'].values\n",
    "    \n",
    "    recommendations = []\n",
    "    for review, place_type in zip(user_reviews, user_types):\n",
    "        type_encoded = type_encoder.transform([place_type])\n",
    "        user_input = {\n",
    "            'types_encoded': np.array(type_encoded),\n",
    "            'review': np.array([review])\n",
    "        }\n",
    "        predictions = model.predict(user_input)\n",
    "        recommended_place_ids = np.argsort(predictions[0])[-5:][::-1]\n",
    "        recommendations.extend(place_encoder.inverse_transform(recommended_place_ids))\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Example of making recommendations\n",
    "user_cuid = \"cp8gyzxgi9766uylq0jc3hkrq\"\n",
    "recommendations = recommend(user_cuid, model, df, place_encoder, type_encoder)\n",
    "print(\"Recommended places:\", recommendations)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "caaa14f5ba97d3f8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# Make recommendations\n",
    "def recommend(user_cuid, model, df, place_encoder, type_encoder):\n",
    "    user_reviews = df[df['user_cuid'] == user_cuid]['review'].values\n",
    "    user_types = df[df['user_cuid'] == user_cuid]['types'].values\n",
    "\n",
    "    recommendations = []\n",
    "    for review, place_type in zip(user_reviews, user_types):\n",
    "        type_encoded = type_encoder.transform([place_type])\n",
    "        user_input = {\n",
    "            'types_encoded': np.array(type_encoded),\n",
    "            'review': np.array([review])\n",
    "        }\n",
    "        predictions = model.predict(user_input)\n",
    "        recommended_place_ids = np.argsort(predictions[0])[-5:][::-1]\n",
    "        recommendations.extend(place_encoder.inverse_transform(recommended_place_ids))\n",
    "        # drop duplicates\n",
    "        recommendations = list(set(recommendations))\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "# Example of making recommendations\n",
    "selected_cuid = \"cdmnbu1268093imcrbhl9wsu9\"\n",
    "\n",
    "user_cuid = df.sample(1)['user_cuid'].values[0]\n",
    "\n",
    "df_place = pd.read_csv('final-dataset/main_dataset.csv')\n",
    "\n",
    "recommendations = recommend(user_cuid, model, df, place_encoder, type_encoder)\n",
    "print(f\"Recommended places for {user_cuid}:\")\n",
    "# print that user reviews\n",
    "print(df[df['user_cuid'] == user_cuid]['review'].values)\n",
    "# print name based on place_id\n",
    "for place_id in recommendations:\n",
    "    print(df_place[df_place['id'] == place_id]['name'].values)\n",
    "    \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d353c83dac7ad6b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.save('collab_modelVwhatever.keras')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b03792193d1facb7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "dd9590ebbfdcef14",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
