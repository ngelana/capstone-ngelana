{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'combined-dataset/final_reviews_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Encode the 'types' column\n",
    "label_encoder = LabelEncoder()\n",
    "data['types_encoded'] = label_encoder.fit_transform(data['types'])\n",
    "\n",
    "# Tokenize the 'review' column\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['review'])\n",
    "sequences = tokenizer.texts_to_sequences(data['review'])\n",
    "\n",
    "# Pad the sequences\n",
    "max_sequence_length = max(len(seq) for seq in sequences)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Create the feature set\n",
    "X = {\n",
    "    'review': padded_sequences,\n",
    "    'types': data['types_encoded'].values,\n",
    "}\n",
    "\n",
    "# Normalize the sentiment scores\n",
    "y = data['sentiment'].values\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T15:16:51.098925800Z",
     "start_time": "2024-06-12T15:16:47.790981100Z"
    }
   },
   "id": "4fce0614da3d08b4",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m547s\u001B[0m 665ms/step - loss: 0.8965 - mae: 0.5329 - val_loss: 0.0898 - val_mae: 0.2247\n",
      "Epoch 2/10\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m613s\u001B[0m 748ms/step - loss: 0.0527 - mae: 0.1662 - val_loss: 0.0548 - val_mae: 0.1634\n",
      "Epoch 3/10\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m646s\u001B[0m 789ms/step - loss: 0.0295 - mae: 0.1219 - val_loss: 0.0413 - val_mae: 0.1388\n",
      "Epoch 4/10\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m591s\u001B[0m 721ms/step - loss: 0.0163 - mae: 0.0901 - val_loss: 0.0374 - val_mae: 0.1339\n",
      "Epoch 5/10\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m501s\u001B[0m 611ms/step - loss: 0.0120 - mae: 0.0781 - val_loss: 0.0327 - val_mae: 0.1201\n",
      "Epoch 6/10\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m505s\u001B[0m 617ms/step - loss: 0.0095 - mae: 0.0683 - val_loss: 0.0301 - val_mae: 0.1160\n",
      "Epoch 7/10\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m506s\u001B[0m 617ms/step - loss: 0.0082 - mae: 0.0647 - val_loss: 0.0278 - val_mae: 0.1123\n",
      "Epoch 8/10\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m503s\u001B[0m 615ms/step - loss: 0.0064 - mae: 0.0566 - val_loss: 0.0264 - val_mae: 0.1076\n",
      "Epoch 9/10\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m480s\u001B[0m 586ms/step - loss: 0.0059 - mae: 0.0538 - val_loss: 0.0266 - val_mae: 0.1087\n",
      "Epoch 10/10\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m485s\u001B[0m 592ms/step - loss: 0.0047 - mae: 0.0500 - val_loss: 0.0245 - val_mae: 0.1056\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.history.History at 0x20ac6134290>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define input layers\n",
    "review_input = Input(shape=(max_sequence_length,), name='review')\n",
    "types_input = Input(shape=(1,), name='types')\n",
    "\n",
    "# Define embedding and LSTM layers for review input\n",
    "review_embedding = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128)(review_input)\n",
    "review_lstm = LSTM(128)(review_embedding)\n",
    "\n",
    "# Define embedding layer for types input\n",
    "types_embedding = Embedding(input_dim=data['types_encoded'].nunique(), output_dim=10)(types_input)\n",
    "types_flat = tf.keras.layers.Flatten()(types_embedding)\n",
    "\n",
    "# Concatenate the review and types embeddings\n",
    "concatenated = Concatenate()([review_lstm, types_flat])\n",
    "\n",
    "# Add dense layers for final prediction\n",
    "dense_1 = Dense(128, activation='relu')(concatenated)\n",
    "dense_2 = Dense(64, activation='relu')(dense_1)\n",
    "output = Dense(1, activation='linear')(dense_2)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[review_input, types_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "model.fit([X['review'], X['types']], y, epochs=10, batch_size=32, validation_split=0.2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T16:46:29.176501900Z",
     "start_time": "2024-06-12T15:16:51.096924800Z"
    }
   },
   "id": "16764ec0f1acbb1f",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1024/1024\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m195s\u001B[0m 190ms/step\n",
      "                                id  \\\n",
      "0      ChIJYcGr7GSb0S0RckePBrCWikw   \n",
      "26459  ChIJs5sHkDub0S0Rs6_ArAb6GYw   \n",
      "14966  ChIJoxOsRvY90i0RfdRmmjHBxDs   \n",
      "2445   ChIJVWVU7lI60i0ROjIjerOky-4   \n",
      "27601  ChIJ8QkA6MQi0i0RJwJqRqijNpc   \n",
      "1304   ChIJQTrID1IF0i0REGYdKOXKObk   \n",
      "3288   ChIJw5Yz3ZU50i0R2RDRqJsUvAs   \n",
      "26714  ChIJ5ZNHoDeJ0S0RhyP0FmUFXBQ   \n",
      "7369   ChIJ-UX-z8wg0i0R2t1WpZDLVDA   \n",
      "14808  ChIJ0__EiSM90i0Rh-u4ELIOCcQ   \n",
      "\n",
      "                                                types review_number  \\\n",
      "0                                      hotel, lodging      review 1   \n",
      "26459                                restaurant, food      review 5   \n",
      "14966            italian_restaurant, restaurant, food      review 3   \n",
      "2445          indonesian_restaurant, restaurant, food      review 1   \n",
      "27601  indonesian_restaurant, restaurant, food, store      review 5   \n",
      "1304       restaurant, coffee_shop, cafe, food, store      review 1   \n",
      "3288                                   hotel, lodging      review 1   \n",
      "26714          fast_food_restaurant, restaurant, food      review 5   \n",
      "7369          indonesian_restaurant, restaurant, food      review 2   \n",
      "14808               thai_restaurant, restaurant, food      review 3   \n",
      "\n",
      "                                                  review     user_id  \\\n",
      "0      It has quite small room, and the hallway is qu...  user_18425   \n",
      "26459  All the appetizers were delicious as well as t...   user_1070   \n",
      "14966  Best Italian restorant in Ubud period. Great l...   user_8888   \n",
      "2445   Regardless of the place called themself as Pad...  user_43900   \n",
      "27601  The fish is super good!! And it's affordable.\\...  user_19046   \n",
      "1304   Beautiful view, amazing food and super friendl...  user_36525   \n",
      "3288   Lovely hotel! So beautiful and aesthetic. We h...   user_5863   \n",
      "26714  It's a typical fastfood Ack friend chicken pla...  user_43551   \n",
      "7369   First tinder having babi guling , was deliciou...  user_27256   \n",
      "14808  We tried eating Thai food at this restaurant y...  user_26829   \n",
      "\n",
      "       sentiment  types_encoded  \n",
      "0           3.02            381  \n",
      "26459       3.83            719  \n",
      "14966       4.35            497  \n",
      "2445        3.00            469  \n",
      "27601       3.78            470  \n",
      "1304        3.98            709  \n",
      "3288        3.91            381  \n",
      "26714       2.72            274  \n",
      "7369        3.91            469  \n",
      "14808       3.86            858  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to get recommendations based on a place ID\n",
    "def get_recommendations(place_id, data, model, top_n=10):\n",
    "    place_idx = data[data['id'] == place_id].index[0]\n",
    "    place_review = X['review'][place_idx]\n",
    "    place_types = X['types'][place_idx]\n",
    "\n",
    "    # Predict the sentiment for all places\n",
    "    predicted_sentiments = model.predict([X['review'], X['types']])\n",
    "\n",
    "    # Calculate similarity\n",
    "    place_vector = np.concatenate([place_review, [place_types]])\n",
    "    all_vectors = np.hstack([X['review'], X['types'].reshape(-1, 1)])\n",
    "    similarities = cosine_similarity([place_vector], all_vectors)[0]\n",
    "\n",
    "    # Get top N similar places\n",
    "    similar_indices = np.argsort(similarities)[-top_n:][::-1]\n",
    "    similar_places = data.iloc[similar_indices]\n",
    "\n",
    "    return similar_places\n",
    "\n",
    "# Example usage\n",
    "place_id = 'ChIJYcGr7GSb0S0RckePBrCWikw'  # Replace with an actual place ID from your dataset\n",
    "recommendations = get_recommendations(place_id, data, model, top_n=10)\n",
    "print(recommendations)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T16:49:53.742500700Z",
     "start_time": "2024-06-12T16:46:35.759117400Z"
    }
   },
   "id": "ade66f54ef88bcd5",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('39_test_model.keras')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T17:24:48.171854200Z",
     "start_time": "2024-06-12T17:24:47.858653900Z"
    }
   },
   "id": "6c28122d45aa642c",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anton\\PycharmProjects\\BangkitStuff\\capstone-ngelana\\.venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 13 variables whereas the saved optimizer has 24 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = tf.keras.models.load_model('39_test_model.keras')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T17:24:49.440668400Z",
     "start_time": "2024-06-12T17:24:48.723987300Z"
    }
   },
   "id": "8f8b901fff697f59",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random place :ChIJlyzLUMdG0i0R9uZM0KyN8WA Four Points by Sheraton Bali, Kuta\n",
      "\u001B[1m1024/1024\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m254s\u001B[0m 248ms/step\n"
     ]
    }
   ],
   "source": [
    "df_review = pd.read_csv('combined-dataset/final_reviews_data.csv')\n",
    "df_place = pd.read_csv('combined-dataset/combined_datasetV2.csv')\n",
    "\n",
    "random_place = df_review.sample(1)\n",
    "rand_id = random_place['id'].values[0]\n",
    "print(f'Random place :{rand_id}', df_place[df_place['id'] == rand_id]['name'].values[0])\n",
    "\n",
    "recommendations = get_recommendations(rand_id, df_review, model, top_n=10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T17:52:06.816282100Z",
     "start_time": "2024-06-12T17:47:50.798585300Z"
    }
   },
   "id": "73f3d0d247699c85",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 name  \\\n",
      "1                        Villa Anjing   \n",
      "8     KŌWHAI Restaurant - Nusa Penida   \n",
      "9                    HOME CAFE CANGGU   \n",
      "7                 Paca Bali Transport   \n",
      "0  Four Points by Sheraton Bali, Kuta   \n",
      "6                      Warung Pananda   \n",
      "2                       What The Crab   \n",
      "5                     Bali Dream Ubud   \n",
      "4               Babi Guling Men Janji   \n",
      "3                   Kajeng Rice Field   \n",
      "\n",
      "                                   types_x  rating  \n",
      "1                     guest_house, lodging     3.8  \n",
      "8   restaurant, breakfast_restaurant, food     4.7  \n",
      "9           coffee_shop, cafe, food, store     4.3  \n",
      "7                               car_rental     5.0  \n",
      "0                           hotel, lodging     4.5  \n",
      "6                         restaurant, food     4.7  \n",
      "2     seafood_restaurant, restaurant, food     4.6  \n",
      "5             resort_hotel, hotel, lodging     4.0  \n",
      "4  indonesian_restaurant, restaurant, food     4.4  \n",
      "3                       tourist_attraction     4.6  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Merge the recommendations with place names based on 'id'\n",
    "merged_recommendations = recommendations.merge(df_place, on='id')\n",
    "# sort reccomendations by sentiment\n",
    "sorted_reccomendations = merged_recommendations.sort_values(by='sentiment', ascending=False)\n",
    "# Print the recommendations with place names with out rand_ind\n",
    "print(sorted_reccomendations[['name','types_x', 'rating']])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T17:52:06.821820300Z",
     "start_time": "2024-06-12T17:52:06.769729600Z"
    }
   },
   "id": "c6dc751da34a7a4b",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "774efa3b0ffded2d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
