{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate, Flatten\n",
    "from keras_tuner import RandomSearch, HyperModel\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'combined-dataset/final_reviews_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Encode the 'types' column\n",
    "label_encoder = LabelEncoder()\n",
    "data['types_encoded'] = label_encoder.fit_transform(data['types'])\n",
    "\n",
    "# Tokenize the 'review' column\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['review'])\n",
    "sequences = tokenizer.texts_to_sequences(data['review'])\n",
    "\n",
    "# Pad the sequences\n",
    "max_sequence_length = max(len(seq) for seq in sequences)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Create the feature set\n",
    "X = {\n",
    "    'review': padded_sequences,\n",
    "    'types': data['types_encoded'].values,\n",
    "}\n",
    "\n",
    "# Normalize the sentiment scores\n",
    "y = data['sentiment'].values\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T20:10:03.383582Z",
     "start_time": "2024-06-12T20:09:59.969113Z"
    }
   },
   "id": "4fce0614da3d08b4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-13 03:10:00.382762: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-13 03:10:00.382816: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-13 03:10:00.383357: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-13 03:10:00.387139: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-13 03:10:00.920795: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "# # Define input layers\n",
    "# review_input = Input(shape=(max_sequence_length,), name='review')\n",
    "# types_input = Input(shape=(1,), name='types')\n",
    "# \n",
    "# # Define embedding and LSTM layers for review input\n",
    "# review_embedding = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128)(review_input)\n",
    "# review_lstm = LSTM(128)(review_embedding)\n",
    "# \n",
    "# # Define embedding layer for types input\n",
    "# types_embedding = Embedding(input_dim=data['types_encoded'].nunique(), output_dim=10)(types_input)\n",
    "# types_flat = tf.keras.layers.Flatten()(types_embedding)\n",
    "# \n",
    "# # Concatenate the review and types embeddings\n",
    "# concatenated = Concatenate()([review_lstm, types_flat])\n",
    "# \n",
    "# # Add dense layers for final prediction\n",
    "# dense_1 = Dense(128, activation='relu')(concatenated)\n",
    "# dense_2 = Dense(64, activation='relu')(dense_1)\n",
    "# output = Dense(1, activation='linear')(dense_2)\n",
    "# \n",
    "# # Create the model\n",
    "# model = Model(inputs=[review_input, types_input], outputs=output)\n",
    "# model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "# \n",
    "# # Train the model\n",
    "# model.fit([X['review'], X['types']], y, epochs=10, batch_size=32, validation_split=0.2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T20:10:03.387602Z",
     "start_time": "2024-06-12T20:10:03.385100Z"
    }
   },
   "id": "16764ec0f1acbb1f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T20:10:03.422132Z",
     "start_time": "2024-06-12T20:10:03.389003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SentimentHyperModel(HyperModel):\n",
    "    def build(self, hp):\n",
    "        review_input = Input(shape=(max_sequence_length,), name='review')\n",
    "        types_input = Input(shape=(1,), name='types')\n",
    "\n",
    "        # Define embedding and LSTM layers for review input\n",
    "        embedding_output_dim = hp.Int('embedding_output_dim', min_value=64, max_value=256, step=32)\n",
    "        lstm_units = hp.Int('lstm_units', min_value=64, max_value=256, step=32)\n",
    "        review_embedding = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=embedding_output_dim)(review_input)\n",
    "        review_lstm = LSTM(units=lstm_units)(review_embedding)\n",
    "\n",
    "        # Define embedding layer for types input\n",
    "        types_embedding = Embedding(input_dim=data['types_encoded'].nunique(), output_dim=10)(types_input)\n",
    "        types_flat = Flatten()(types_embedding)\n",
    "\n",
    "        # Concatenate the review and types embeddings\n",
    "        concatenated = Concatenate()([review_lstm, types_flat])\n",
    "\n",
    "        # Add dense layers for final prediction\n",
    "        dense_units_1 = hp.Int('dense_units_1', min_value=64, max_value=256, step=32)\n",
    "        dense_units_2 = hp.Int('dense_units_2', min_value=32, max_value=128, step=16)\n",
    "        dense_1 = Dense(units=dense_units_1, activation='relu')(concatenated)\n",
    "        dense_2 = Dense(units=dense_units_2, activation='relu')(dense_1)\n",
    "        output = Dense(1, activation='linear')(dense_2)\n",
    "\n",
    "        # Choose an optimizer\n",
    "        optimizer_choice = hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop'])\n",
    "\n",
    "        if optimizer_choice == 'adam':\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log'))\n",
    "        elif optimizer_choice == 'sgd':\n",
    "            optimizer = tf.keras.optimizers.SGD(learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log'))\n",
    "        elif optimizer_choice == 'rmsprop':\n",
    "            optimizer = tf.keras.optimizers.RMSprop(learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log'))\n",
    "\n",
    "        # Create the model\n",
    "        model = Model(inputs=[review_input, types_input], outputs=output)\n",
    "        model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "        return model"
   ],
   "id": "7a8333f8e323cb4b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tuner = RandomSearch(\n",
    "    hypermodel=SentimentHyperModel(),\n",
    "    objective='val_loss',\n",
    "    max_trials=10,  # Number of different hyperparameter sets to try\n",
    "    executions_per_trial=2,  # Number of models to train with the same hyperparameters\n",
    "    directory='model-testing',\n",
    "    project_name='sentiment_tuning'\n",
    ")\n",
    "\n",
    "# %%\n",
    "# Search for the best hyperparameters\n",
    "tuner.search([X['review'], X['types']], y, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Build the best model\n",
    "best_model = tuner.hypermodel.build(best_hps)"
   ],
   "id": "633172108e147ab3",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 19m 27s]\n",
      "val_loss: 0.044572435319423676\n",
      "\n",
      "Best val_loss So Far: 0.021111944690346718\n",
      "Total elapsed time: 02h 56m 37s\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T23:14:12.646107Z",
     "start_time": "2024-06-12T23:06:41.211973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_model.fit([X['review'], X['types']], y, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# %%\n",
    "# Save the best model\n",
    "best_model.save('best_sentiment_model.keras')"
   ],
   "id": "2d8966f7cb395973",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "819/819 [==============================] - 57s 68ms/step - loss: 0.4950 - mae: 0.4112 - val_loss: 0.0898 - val_mae: 0.2228\n",
      "Epoch 2/10\n",
      "819/819 [==============================] - 47s 57ms/step - loss: 0.0798 - mae: 0.2160 - val_loss: 0.1203 - val_mae: 0.2994\n",
      "Epoch 3/10\n",
      "819/819 [==============================] - 45s 55ms/step - loss: 0.0430 - mae: 0.1572 - val_loss: 0.0308 - val_mae: 0.1203\n",
      "Epoch 4/10\n",
      "819/819 [==============================] - 45s 55ms/step - loss: 0.0286 - mae: 0.1297 - val_loss: 0.0518 - val_mae: 0.1859\n",
      "Epoch 5/10\n",
      "819/819 [==============================] - 44s 54ms/step - loss: 0.0226 - mae: 0.1158 - val_loss: 0.0305 - val_mae: 0.1245\n",
      "Epoch 6/10\n",
      "819/819 [==============================] - 43s 52ms/step - loss: 0.0187 - mae: 0.1051 - val_loss: 0.0320 - val_mae: 0.1323\n",
      "Epoch 7/10\n",
      "819/819 [==============================] - 42s 51ms/step - loss: 0.0160 - mae: 0.0971 - val_loss: 0.0217 - val_mae: 0.0982\n",
      "Epoch 8/10\n",
      "819/819 [==============================] - 43s 53ms/step - loss: 0.0141 - mae: 0.0923 - val_loss: 0.0459 - val_mae: 0.1748\n",
      "Epoch 9/10\n",
      "819/819 [==============================] - 43s 52ms/step - loss: 0.0128 - mae: 0.0879 - val_loss: 0.0361 - val_mae: 0.1430\n",
      "Epoch 10/10\n",
      "819/819 [==============================] - 42s 52ms/step - loss: 0.0119 - mae: 0.0850 - val_loss: 0.0232 - val_mae: 0.1059\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T23:14:14.849562Z",
     "start_time": "2024-06-12T23:14:12.647500Z"
    }
   },
   "cell_type": "code",
   "source": "model = tf.keras.models.load_model('best_sentiment_model.keras')",
   "id": "8bf1e691a2787bfd",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to get recommendations based on a place ID\n",
    "def get_recommendations(place_id, data, model, top_n=10):\n",
    "    place_idx = data[data['id'] == place_id].index[0]\n",
    "    place_review = X['review'][place_idx]\n",
    "    place_types = X['types'][place_idx]\n",
    "\n",
    "    # Predict the sentiment for all places\n",
    "    predicted_sentiments = model.predict([X['review'], X['types']])\n",
    "\n",
    "    # Calculate similarity\n",
    "    place_vector = np.concatenate([place_review, [place_types]])\n",
    "    all_vectors = np.hstack([X['review'], X['types'].reshape(-1, 1)])\n",
    "    similarities = cosine_similarity([place_vector], all_vectors)[0]\n",
    "\n",
    "    # Get top N similar places\n",
    "    similar_indices = np.argsort(similarities)[-top_n:][::-1]\n",
    "    similar_places = data.iloc[similar_indices]\n",
    "\n",
    "    return similar_places\n",
    "\n",
    "# Example usage\n",
    "place_id = 'ChIJYcGr7GSb0S0RckePBrCWikw'  # Replace with an actual place ID from your dataset\n",
    "recommendations = get_recommendations(place_id, data, model, top_n=10)\n",
    "print(recommendations)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T23:14:36.666148Z",
     "start_time": "2024-06-12T23:14:14.850850Z"
    }
   },
   "id": "ade66f54ef88bcd5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024/1024 [==============================] - 21s 20ms/step\n",
      "                                id                                    types  \\\n",
      "0      ChIJYcGr7GSb0S0RckePBrCWikw                           hotel, lodging   \n",
      "9397   ChIJMx5rxaE_0i0Rs0e7AyFBAc4                         restaurant, food   \n",
      "26459  ChIJs5sHkDub0S0Rs6_ArAb6GYw                         restaurant, food   \n",
      "24537  ChIJy1yJjCFH0i0REyjNQfSK0Vw            cafe, store, restaurant, food   \n",
      "2445   ChIJVWVU7lI60i0ROjIjerOky-4  indonesian_restaurant, restaurant, food   \n",
      "26714  ChIJ5ZNHoDeJ0S0RhyP0FmUFXBQ   fast_food_restaurant, restaurant, food   \n",
      "7369   ChIJ-UX-z8wg0i0R2t1WpZDLVDA  indonesian_restaurant, restaurant, food   \n",
      "17727  ChIJpXrQ0Hhz0i0RlgGmL0UEIcE                          hostel, lodging   \n",
      "14808  ChIJ0__EiSM90i0Rh-u4ELIOCcQ        thai_restaurant, restaurant, food   \n",
      "21670  ChIJzUP7KWk90i0RawIr0Sl0yyM                           hotel, lodging   \n",
      "\n",
      "      review_number                                             review  \\\n",
      "0          review 1  It has quite small room, and the hallway is qu...   \n",
      "9397       review 2  Burger √\\r\\nIce cream needs more creamy.\\r\\nCh...   \n",
      "26459      review 5  All the appetizers were delicious as well as t...   \n",
      "24537      review 4  Was really looking forward to coming here. The...   \n",
      "2445       review 1  Regardless of the place called themself as Pad...   \n",
      "26714      review 5  It's a typical fastfood Ack friend chicken pla...   \n",
      "7369       review 2  First tinder having babi guling , was deliciou...   \n",
      "17727      review 3  Cons:\\r\\nEach bed has a noisy ventilation fan ...   \n",
      "14808      review 3  We tried eating Thai food at this restaurant y...   \n",
      "21670      review 4  10 ⭐️ !! Hotel bed & pillows were amazingly co...   \n",
      "\n",
      "          user_id  sentiment  types_encoded  \n",
      "0      user_18425       3.02            381  \n",
      "9397   user_48219       2.73            719  \n",
      "26459   user_1070       3.83            719  \n",
      "24537  user_33432       3.51            174  \n",
      "2445   user_43900       3.00            469  \n",
      "26714  user_43551       2.72            274  \n",
      "7369   user_27256       3.91            469  \n",
      "17727  user_63932       4.56            346  \n",
      "14808  user_26829       3.86            858  \n",
      "21670  user_20719       3.91            381  \n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "# Save the model\n",
    "# model.save('39_test_model.keras')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T23:14:36.673250Z",
     "start_time": "2024-06-12T23:14:36.668621Z"
    }
   },
   "id": "6c28122d45aa642c",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the model\n",
    "# model = tf.keras.models.load_model('39_test_model.keras')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T23:14:36.701164Z",
     "start_time": "2024-06-12T23:14:36.674340Z"
    }
   },
   "id": "8f8b901fff697f59",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "df_review = pd.read_csv('combined-dataset/final_reviews_data.csv')\n",
    "df_place = pd.read_csv('combined-dataset/combined_datasetV2.csv')\n",
    "\n",
    "random_place = df_review.sample(1)\n",
    "rand_id = random_place['id'].values[0]\n",
    "print(f'Random place :{rand_id}', df_place[df_place['id'] == rand_id]['name'].values[0])\n",
    "\n",
    "recommendations = get_recommendations(rand_id, df_review, model, top_n=10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T23:14:57.603632Z",
     "start_time": "2024-06-12T23:14:36.702111Z"
    }
   },
   "id": "73f3d0d247699c85",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random place :ChIJE6JRPEv10S0RXGpICmBZF0g Mutiara Resto Kintamani\n",
      "1024/1024 [==============================] - 20s 19ms/step\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# Merge the recommendations with place names based on 'id'\n",
    "merged_recommendations = recommendations.merge(df_place, on='id')\n",
    "# sort reccomendations by sentiment\n",
    "sorted_reccomendations = merged_recommendations.sort_values(by='sentiment', ascending=False)\n",
    "# Print the recommendations with place names with out rand_ind\n",
    "print(sorted_reccomendations[['name','types_x', 'rating']])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T23:14:57.635189Z",
     "start_time": "2024-06-12T23:14:57.604704Z"
    }
   },
   "id": "c6dc751da34a7a4b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       name  \\\n",
      "8          Kampuak Cottages   \n",
      "4                Tulen Ubud   \n",
      "1   Teba Junjungan Cottages   \n",
      "7               Il Pomodoro   \n",
      "3             Ayu Tamansari   \n",
      "0   Mutiara Resto Kintamani   \n",
      "9     Guling Samsam Merekak   \n",
      "2  Sea Breeze Cafe Ceningan   \n",
      "6            Villa Anjing 2   \n",
      "5           Taman Indrakila   \n",
      "\n",
      "                                             types_x  rating  \n",
      "8                                            lodging     4.9  \n",
      "4                                   restaurant, food     4.7  \n",
      "1                         bed_and_breakfast, lodging     4.5  \n",
      "7  italian_restaurant, pizza_restaurant, restaura...     4.5  \n",
      "3                                     hotel, lodging     4.5  \n",
      "0                                   restaurant, food     4.0  \n",
      "9            indonesian_restaurant, restaurant, food     4.6  \n",
      "2                              restaurant, bar, food     4.5  \n",
      "6                                     hotel, lodging     3.5  \n",
      "5                                     hotel, lodging     4.1  \n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T23:14:57.641383Z",
     "start_time": "2024-06-12T23:14:57.636382Z"
    }
   },
   "id": "774efa3b0ffded2d",
   "outputs": [],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
