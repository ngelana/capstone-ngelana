{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import os and disable tensorflow warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '5'"
   ],
   "id": "6ebcabf4035e585e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate, Flatten, BatchNormalization, Dropout"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load reviews dataset\n",
    "reviews_path = 'combined-dataset/final_reviews_data.csv'\n",
    "data = pd.read_csv(reviews_path)"
   ],
   "id": "f7b038c9cb41e6e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Encode types column and Tokenize reviews column\n",
    "encoder = LabelEncoder()\n",
    "data['types_encoded'] = encoder.fit_transform(data['types'])\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['review'])\n",
    "sequences = tokenizer.texts_to_sequences(data['review'])\n",
    "\n",
    "# Pad sequences\n",
    "max_sequence_length = max(map(len, sequences), default=0)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)"
   ],
   "id": "4da0dc0a0eafd922",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create features set and normalize sentiment for label\n",
    "X = {\n",
    "    'review': padded_sequences,\n",
    "    'types': data['types_encoded'].values\n",
    "}\n",
    "\n",
    "Y = data['sentiment'].values"
   ],
   "id": "735d3200ac566cc6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Define Models Layer\n",
    "# Input\n",
    "review_input = Input(shape=(max_sequence_length,), name='review')\n",
    "types_input = Input(shape=(1,), name='types')\n",
    "\n",
    "# Embedding and LSTM for review\n",
    "review_embedding = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64)(review_input)\n",
    "review_lstm = LSTM(64)(review_embedding)\n",
    "\n",
    "# Embedding and Flatten for types\n",
    "types_embedding = Embedding(input_dim=len(encoder.classes_), output_dim=64)(types_input)\n",
    "types_flat = Flatten()(types_embedding)\n",
    "\n",
    "# Concatenate review and types\n",
    "concatenated = Concatenate()([review_lstm, types_flat])\n",
    "\n",
    "# Dense layers\n",
    "dense_1 = Dense(64, activation='relu')(concatenated)\n",
    "batch_1 = BatchNormalization()(dense_1)\n",
    "dropout_1 = Dropout(0.2)(batch_1)\n",
    "\n",
    "# dense_2 = Dense(64, activation='relu')(dropout_1)\n",
    "# batch_2 = BatchNormalization()(dense_2)\n",
    "# dropout_2 = Dropout(0.2)(batch_2)\n",
    "# \n",
    "# dense_3 = Dense(32, activation='relu')(dropout_2)\n",
    "# batch_3 = BatchNormalization()(dense_3)\n",
    "# dropout_3 = Dropout(0.2)(batch_3)\n",
    "\n",
    "output = Dense(1, activation='linear')(dropout_1)"
   ],
   "id": "d35ca5119b28e81",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create and Compile the Model\n",
    "model = Model(inputs=[review_input, types_input], outputs=output)\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ],
   "id": "529b41a5646223ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)",
   "id": "bb619e910897f917",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.fit([X['review'], X['types']], Y, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping])",
   "id": "17c67482d2170dec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "loss, mae = model.evaluate([X['review'], X['types']], Y)\n",
    "print(f'Model has a loss of {loss} and a mean absolute error of {mae}')"
   ],
   "id": "24db372305494fb7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.save('ml_model.keras')",
   "id": "9594917d70fd68b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "content_model = load_model('ml_model.keras')",
   "id": "c17460a77455d087",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_place_recommendations(model, place_id, dataset, top_n=10):\n",
    "    place_idx = dataset[dataset['id'] == place_id].index[0]\n",
    "    place_review = X['review'][place_idx]\n",
    "    place_types = X['types'][place_idx]\n",
    "    \n",
    "    predicted_sentiments = model.predict([X['review'], X['types']])\n",
    "    \n",
    "    place_vector = np.concatenate([place_review, [place_types]])\n",
    "    all_vector = np.hstack([X['review'], X['types'].reshape(-1, 1)])\n",
    "    similarities = cosine_similarity([place_vector], all_vector)[0]\n",
    "    \n",
    "    similar_indices = np.argsort(similarities)[-top_n:][::-1]\n",
    "    similar_places = dataset.iloc[similar_indices]\n",
    "    \n",
    "    return similar_places, predicted_sentiments[similar_indices]"
   ],
   "id": "58cd422bb1961c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "place_id = 'ChIJIaGQ-Eg60i0RnT9pzyD_gvM'\n",
    "\n",
    "recommendations = get_place_recommendations(content_model, place_id, data)\n",
    "print(recommendations)"
   ],
   "id": "976655150aad0ac4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "12009ae30f9098fe",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
